package proxy

import (
	"bufio"
	"context"
	"fmt"
	"io"
	"log/slog"
	"net/http"
	"strings"
	"sync"
	"time"

	"cc-forwarder/internal/proxy/response"
	"cc-forwarder/internal/tracking"
	"cc-forwarder/internal/utils"
)

// ç¼“å†²åŒºå¤§å°å¸¸é‡
const (
	StreamBufferSize     = 8192 // 8KBä¸»ç¼“å†²åŒº
	LineBufferInitSize   = 1024 // 1KBè¡Œç¼“å†²åŒºåˆå§‹å¤§å°
	BackgroundBufferSize = 4096 // 4KBåå°è§£æç¼“å†²åŒº
	DebugLineLimit       = 100  // è°ƒè¯•æ¨¡å¼ä¸‹æœ€å¤šä¿å­˜100è¡ŒSSEæ•°æ®
)

// StreamProcessor æµå¼å¤„ç†å™¨æ ¸å¿ƒç»“æ„ä½“
type StreamProcessor struct {
	// æ ¸å¿ƒç»„ä»¶
	tokenParser    *TokenParser           // Tokenè§£æå™¨ï¼Œç”¨äºæå–æ¨¡å‹ä¿¡æ¯å’Œä½¿ç”¨ç»Ÿè®¡
	usageTracker   *tracking.UsageTracker // ä½¿ç”¨è·Ÿè¸ªå™¨ï¼Œè®°å½•è¯·æ±‚ç”Ÿå‘½å‘¨æœŸ
	responseWriter http.ResponseWriter    // HTTPå“åº”å†™å…¥å™¨
	flusher        http.Flusher           // HTTPåˆ·æ–°å™¨ï¼Œç”¨äºç«‹å³å‘é€æ•°æ®åˆ°å®¢æˆ·ç«¯

	// é”™è¯¯å¤„ç†å’Œæ¢å¤
	errorRecovery *ErrorRecoveryManager // é”™è¯¯æ¢å¤ç®¡ç†å™¨
	lastAPIError  error                 // V2æ¶æ„ï¼šæœ€åä¸€æ¬¡APIé”™è¯¯ä¿¡æ¯

	// è¯·æ±‚æ ‡è¯†ä¿¡æ¯
	requestID string // è¯·æ±‚å”¯ä¸€æ ‡è¯†ç¬¦
	endpoint  string // ç«¯ç‚¹åç§°

	// æµå¼å¤„ç†çŠ¶æ€
	startTime      time.Time // å¤„ç†å¼€å§‹æ—¶é—´
	bytesProcessed int64     // å·²å¤„ç†å­—èŠ‚æ•°
	lineBuffer     []byte    // SSEè¡Œç¼“å†²åŒº
	partialData    []byte    // éƒ¨åˆ†æ•°æ®ç¼“å†²åŒºï¼Œç”¨äºé”™è¯¯æ¢å¤

	// å¹¶å‘æ§åˆ¶
	parseWg    sync.WaitGroup // ç­‰å¾…ç»„ï¼Œç¡®ä¿åå°è§£æå®Œæˆ
	parseMutex sync.Mutex     // è§£æäº’æ–¥é”ï¼Œä¿æŠ¤å…±äº«çŠ¶æ€

	// é”™è¯¯å¤„ç†
	parseErrors    []error // è§£æè¿‡ç¨‹ä¸­çš„é”™è¯¯é›†åˆ
	maxParseErrors int     // æœ€å¤§å…è®¸è§£æé”™è¯¯æ•°

	// å®ŒæˆçŠ¶æ€è·Ÿè¸ª
	completionRecorded bool // æ˜¯å¦å·²ç»è®°å½•å®ŒæˆçŠ¶æ€ï¼Œé˜²æ­¢é‡å¤è®°å½•

	// ğŸ” [è°ƒè¯•ç¼“å†²åŒº] è½»é‡çº§è°ƒè¯•æ•°æ®æ”¶é›†ï¼ˆä»…åœ¨tokenè§£æå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
	debugLines []string // SSEè¡Œæ•°æ®æ”¶é›†ï¼Œæœ€å¤šä¿å­˜DebugLineLimitè¡Œ
}

// NewStreamProcessor åˆ›å»ºæ–°çš„æµå¼å¤„ç†å™¨å®ä¾‹
func NewStreamProcessor(tokenParser *TokenParser, usageTracker *tracking.UsageTracker,
	w http.ResponseWriter, flusher http.Flusher, requestID, endpoint string) *StreamProcessor {

	sp := &StreamProcessor{
		tokenParser:    tokenParser,
		usageTracker:   usageTracker,
		responseWriter: w,
		flusher:        flusher,
		errorRecovery:  NewErrorRecoveryManager(usageTracker),
		requestID:      requestID,
		endpoint:       endpoint,
		startTime:      time.Now(),
		lineBuffer:     make([]byte, 0, LineBufferInitSize),
		partialData:    make([]byte, 0, BackgroundBufferSize),
		maxParseErrors: 10,                                // æœ€å¤šå…è®¸10ä¸ªè§£æé”™è¯¯
		debugLines:     make([]string, 0, DebugLineLimit), // ğŸ” [è°ƒè¯•] åˆå§‹åŒ–è°ƒè¯•ç¼“å†²åŒº
	}

	return sp
}

// ProcessStream å®ç°è¾¹æ¥æ”¶è¾¹è½¬å‘çš„8KBç¼“å†²åŒºæµå¼å¤„ç†
// è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œå®ç°çœŸæ­£çš„æµå¼å¤„ç†æœºåˆ¶
func (sp *StreamProcessor) ProcessStream(ctx context.Context, resp *http.Response) (*tracking.TokenUsage, error) {
	defer resp.Body.Close()
	defer sp.waitForBackgroundParsing() // ç¡®ä¿æ‰€æœ‰åå°è§£æå®Œæˆ

	// ğŸ”§ [è§£å‹ç¼©ä¿®å¤] åˆ›å»ºå“åº”å¤„ç†å™¨å¹¶è·å–è§£å‹ç¼©çš„æµå¼è¯»å–å™¨
	processor := response.NewProcessor()
	decompressedReader, err := processor.DecompressStreamReader(resp)
	if err != nil {
		return nil, fmt.Errorf("ğŸ—œï¸ [è§£å‹ç¼©å¤±è´¥] [%s] ç«¯ç‚¹: %s, é”™è¯¯: %w", sp.requestID, sp.endpoint, err)
	}
	defer decompressedReader.Close() // ç¡®ä¿è§£å‹ç¼©è¯»å–å™¨è¢«å…³é—­

	// è®°å½•è§£å‹ç¼©çŠ¶æ€
	contentEncoding := resp.Header.Get("Content-Encoding")
	if contentEncoding != "" {
		slog.Info(fmt.Sprintf("ğŸ—œï¸ [æµå¼è§£å‹] [%s] ç«¯ç‚¹: %s, ç¼–ç : %s", sp.requestID, sp.endpoint, contentEncoding))
	}

	// åˆå§‹åŒ–8KBç¼“å†²åŒºï¼Œä½¿ç”¨è§£å‹ç¼©åçš„è¯»å–å™¨
	buffer := make([]byte, StreamBufferSize)
	reader := bufio.NewReader(decompressedReader)

	// è®°å½•æµå¤„ç†å¼€å§‹
	slog.Info(fmt.Sprintf("ğŸŒŠ [æµå¼å¤„ç†] [%s] å¼€å§‹æµå¼å¤„ç†ï¼Œç«¯ç‚¹: %s", sp.requestID, sp.endpoint))

	// ä¸»æµå¼å¤„ç†å¾ªç¯
	for {
		// æ£€æŸ¥contextå–æ¶ˆ - ä¼˜å…ˆçº§æœ€é«˜
		select {
		case <-ctx.Done():
			// å®¢æˆ·ç«¯å–æ¶ˆï¼Œè¿›å…¥ä¼˜é›…å–æ¶ˆå¤„ç†
			return sp.handleCancellationV2(ctx, ctx.Err())
		default:
			// ç»§ç»­æ­£å¸¸å¤„ç†
		}

		// 1. ä»å“åº”ä¸­è¯»å–æ•°æ®åˆ°8KBç¼“å†²åŒº
		n, err := reader.Read(buffer)

		if n > 0 {
			chunk := buffer[:n]

			// ä¿å­˜éƒ¨åˆ†æ•°æ®ç”¨äºé”™è¯¯æ¢å¤
			sp.savePartialData(chunk)

			// 2. ç«‹å³è½¬å‘åˆ°å®¢æˆ·ç«¯ - è¿™æ˜¯å…³é”®ï¼ä¸ç­‰å¾…å®Œæ•´å“åº”
			if writeErr := sp.forwardToClient(chunk); writeErr != nil {
				// ä½¿ç”¨é”™è¯¯æ¢å¤ç®¡ç†å™¨å¤„ç†è½¬å‘é”™è¯¯
				errorCtx := sp.errorRecovery.ClassifyError(writeErr, sp.requestID, sp.endpoint, "", 0)
				sp.errorRecovery.HandleFinalFailure(errorCtx)
				slog.Error(fmt.Sprintf("âŒ [æµå¼é”™è¯¯] [%s] è½¬å‘åˆ°å®¢æˆ·ç«¯å¤±è´¥: %v", sp.requestID, writeErr))
				return nil, fmt.Errorf("failed to forward to client: %w", writeErr)
			}

			// 3. å¹¶è¡Œè§£æTokenä¿¡æ¯ - ä¸å½±å“è½¬å‘æ€§èƒ½
			sp.parseTokensInBackground(chunk)

			// 4. æ›´æ–°å¤„ç†çŠ¶æ€
			sp.bytesProcessed += int64(n)
		}

		// å¤„ç†è¯»å–ç»“æŸå’Œé”™è¯¯
		if err == io.EOF {
			// ç­‰å¾…æ‰€æœ‰åå°è§£æå®Œæˆ
			sp.waitForBackgroundParsing()

			// è·å–æœ€ç»ˆçš„ Token ä½¿ç”¨ä¿¡æ¯
			finalTokenUsage := sp.getFinalTokenUsage()

			slog.Info(fmt.Sprintf("âœ… [æµå¼å®Œæˆ] [%s] ç«¯ç‚¹: %s, æµå¤„ç†æ­£å¸¸å®Œæˆï¼Œå·²å¤„ç† %d å­—èŠ‚",
				sp.requestID, sp.endpoint, sp.bytesProcessed))
			return finalTokenUsage, nil
		}

		if err != nil {
			// ç½‘ç»œä¸­æ–­æˆ–å…¶ä»–é”™è¯¯ï¼Œå°è¯•éƒ¨åˆ†æ•°æ®å¤„ç†
			return sp.handlePartialStreamV2(err)
		}
	}
}

// forwardToClient ç«‹å³è½¬å‘æ•°æ®åˆ°å®¢æˆ·ç«¯
func (sp *StreamProcessor) forwardToClient(data []byte) error {
	// å†™å…¥æ•°æ®åˆ°å“åº”
	if _, err := sp.responseWriter.Write(data); err != nil {
		return err
	}

	// ç«‹å³åˆ·æ–°ï¼Œç¡®ä¿æ•°æ®ç«‹å³å‘é€åˆ°å®¢æˆ·ç«¯
	sp.flusher.Flush()

	return nil
}

// parseTokensInBackground å¹¶å‘Tokenè§£æï¼Œä¸é˜»å¡ä¸»æµ
// è¿™ä¸ªæ–¹æ³•åœ¨åå°goroutineä¸­è§£æSSEäº‹ä»¶ï¼Œæå–æ¨¡å‹ä¿¡æ¯å’ŒTokenä½¿ç”¨ç»Ÿè®¡
func (sp *StreamProcessor) parseTokensInBackground(data []byte) {
	// ä¸ºæ¯ä¸ªæ•°æ®å—å¯åŠ¨ä¸€ä¸ªåå°goroutine
	sp.parseWg.Add(1)

	go func() {
		defer sp.parseWg.Done()

		// åˆ›å»ºåå°å¤„ç†ç¼“å†²åŒº
		parseBuffer := make([]byte, len(data))
		copy(parseBuffer, data)

		// é€å­—èŠ‚å¤„ç†ï¼Œæ„å»ºSSEè¡Œ
		sp.parseMutex.Lock()
		defer sp.parseMutex.Unlock()

		for _, b := range parseBuffer {
			// æ„å»ºè¡Œç¼“å†²åŒº
			sp.lineBuffer = append(sp.lineBuffer, b)

			// æ£€æµ‹æ¢è¡Œç¬¦ï¼Œå¤„ç†å®Œæ•´çš„SSEè¡Œ
			if b == '\n' {
				line := strings.TrimSpace(string(sp.lineBuffer))

				// âœ… ä¿®å¤ï¼šå¤„ç†æ‰€æœ‰è¡Œï¼ŒåŒ…æ‹¬ç©ºè¡Œï¼ˆç©ºè¡Œè§¦å‘SSEäº‹ä»¶è§£æï¼‰
				sp.processSSELine(line)

				// é‡ç½®è¡Œç¼“å†²åŒºï¼Œå‡†å¤‡ä¸‹ä¸€è¡Œ
				sp.lineBuffer = sp.lineBuffer[:0]
			}
		}
	}()
}

// processSSELine å¤„ç†å•ä¸ªSSEè¡Œ
// ä¿®æ”¹ç‰ˆæœ¬ï¼šä»…è¿›è¡Œ Token è§£æï¼Œä¸å†ç›´æ¥è®°å½•åˆ° usageTracker
func (sp *StreamProcessor) processSSELine(line string) {
	// ğŸ” [è°ƒè¯•æ•°æ®æ”¶é›†] è½»é‡çº§æ”¶é›†SSEè¡Œæ•°æ®ï¼ˆæ— æ€§èƒ½å½±å“ï¼‰
	if len(sp.debugLines) < DebugLineLimit {
		sp.debugLines = append(sp.debugLines, line)
	}

	// âœ… ä½¿ç”¨V2æ¶æ„è¿›è¡Œè§£æ
	result := sp.tokenParser.ParseSSELineV2(line)

	if result != nil {
		// âœ… æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
		if result.ErrorInfo != nil {
			// V2æ¶æ„ï¼šå¤„ç†APIé”™è¯¯ä¿¡æ¯
			slog.Error(fmt.Sprintf("âŒ [APIé”™è¯¯V2] [%s] ç±»å‹: %s, æ¶ˆæ¯: %s",
				sp.requestID, result.ErrorInfo.Type, result.ErrorInfo.Message))

			// å°†é”™è¯¯ä¿¡æ¯å­˜å‚¨ï¼Œä¾›ä¸Šå±‚ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å¤„ç†
			sp.lastAPIError = fmt.Errorf("APIé”™è¯¯ %s: %s", result.ErrorInfo.Type, result.ErrorInfo.Message)
			return
		}

		// âœ… å¤„ç†æ­£å¸¸Tokenä¿¡æ¯
		if result.TokenUsage != nil {
			// V2æ¶æ„ï¼šç›´æ¥ä½¿ç”¨ParseResultï¼Œæ— éœ€ç±»å‹è½¬æ¢
			trackingTokens := result.TokenUsage
			modelName := result.ModelName

			// ç¡®ä¿æ¨¡å‹åç§°ä¸ä¸ºç©º
			if modelName == "" {
				modelName = "default"
			}

			// âœ… ç§»é™¤completionRecordedé™åˆ¶ï¼Œæ¯æ¬¡éƒ½æ›´æ–°æœ€æ–°tokenç»Ÿè®¡
			slog.Debug(fmt.Sprintf("ğŸ”„ [Tokenå®æ—¶æ›´æ–°] [%s] æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d",
				sp.requestID, modelName, trackingTokens.InputTokens, trackingTokens.OutputTokens,
				trackingTokens.CacheCreationTokens, trackingTokens.CacheReadTokens))

			// âœ… ç§»é™¤æˆ–æ³¨é‡Šæ‰è¿™ä¸ªå­—æ®µï¼Œå› ä¸ºä¸å†éœ€è¦
			// sp.completionRecorded = true
		}
	}
}

// ensureRequestCompletion ç¡®ä¿è¯·æ±‚å®ŒæˆçŠ¶æ€è¢«è®°å½•ï¼ˆfallbackæœºåˆ¶ï¼‰
// ğŸš« DEPRECATED: å·²è¢« getFinalTokenUsage() æ›¿ä»£ï¼Œæ­¤æ–¹æ³•å·²å®Œå…¨ç§»é™¤è¿è§„è°ƒç”¨
// æ­¤æ–¹æ³•ä¸å†æ‰§è¡Œä»»ä½•æ“ä½œï¼Œä»…ä¿ç•™æ–¹æ³•ç­¾åä»¥ç»´æŒå…¼å®¹æ€§
func (sp *StreamProcessor) ensureRequestCompletion() {
	// âš ï¸ æ­¤æ–¹æ³•å·²å®Œå…¨å¼ƒç”¨ï¼Œæ‰€æœ‰åŠŸèƒ½å·²è¿ç§»åˆ° getFinalTokenUsage() æ–¹æ³•
	// åŸå› ï¼šè¿åå•ä¸€è´£ä»»åŸåˆ™ï¼Œç›´æ¥è°ƒç”¨ usageTracker è€Œéé€šè¿‡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
	//
	// æ–°çš„æ¶æ„è¦æ±‚ï¼š
	// 1. StreamProcessor åªè´Ÿè´£è§£æå’Œè¿”å›Tokenä¿¡æ¯
	// 2. Handler è°ƒç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•å®ŒæˆçŠ¶æ€
	// 3. ä¸å†æœ‰ä»»ä½•ç»„ä»¶ç›´æ¥è°ƒç”¨ usageTracker

	slog.Debug(fmt.Sprintf("âš ï¸ [å·²å¼ƒç”¨] [%s] ensureRequestCompletionå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨getFinalTokenUsage", sp.requestID))
}

// attemptUsageRecovery å¼‚æ­¥å°è¯•ä»debugæ–‡ä»¶æ¢å¤å®Œæ•´çš„usageä¿¡æ¯
// ğŸ”§ [Fallbackä¿®å¤] ç­‰å¾…debugæ–‡ä»¶å†™å…¥å®Œæˆåï¼Œå°è¯•æå–å®Œæ•´çš„tokenä½¿ç”¨ç»Ÿè®¡å¹¶æ›´æ–°æ•°æ®åº“
func (sp *StreamProcessor) attemptUsageRecovery() {
	// ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿debugæ–‡ä»¶å†™å…¥å®Œæˆ
	time.Sleep(2 * time.Second)

	modelName := sp.tokenParser.GetModelName()
	if modelName == "" {
		modelName = "unknown"
	}

	// å°è¯•ä»debugæ–‡ä»¶æ¢å¤usageä¿¡æ¯
	err := utils.RecoverAndUpdateUsage(sp.requestID, modelName, sp.usageTracker)
	if err != nil {
		slog.Warn(fmt.Sprintf("ğŸ”§ [Recoveryå¤±è´¥] [%s] ä»debugæ–‡ä»¶æ¢å¤usageå¤±è´¥: %v", sp.requestID, err))
		return
	}

	slog.Info(fmt.Sprintf("ğŸ”§ [RecoveryæˆåŠŸ] [%s] æˆåŠŸä»debugæ–‡ä»¶æ¢å¤å®Œæ•´çš„usageä¿¡æ¯", sp.requestID))
}

// classifyStreamError æ™ºèƒ½çŠ¶æ€åˆ†ç±»æ–¹æ³•
// ç¡®ä¿ context canceled æ­£ç¡®å½’ç±»ä¸º cancelled è€Œä¸æ˜¯ error
func (sp *StreamProcessor) classifyStreamError(err error, tokenUsage *tracking.TokenUsage) string {
	if err == nil {
		return "success"
	}

	errStr := err.Error()

	// âœ… ä¼˜å…ˆæ£€æµ‹å–æ¶ˆçŠ¶æ€ï¼ˆä¿®å¤æ ¸å¿ƒé—®é¢˜ï¼‰
	if errStr == "context canceled" || strings.Contains(errStr, "context canceled") {
		// æ£€æŸ¥æ˜¯å¦æœ‰tokenä¿¡æ¯ï¼Œç”¨äºæ—¥å¿—åŒºåˆ†
		hasTokens := tokenUsage != nil && (tokenUsage.InputTokens > 0 || tokenUsage.OutputTokens > 0 ||
			tokenUsage.CacheCreationTokens > 0 || tokenUsage.CacheReadTokens > 0)

		if hasTokens {
			slog.Warn(fmt.Sprintf("âš ï¸ [å·²è®¡è´¹å–æ¶ˆ] [%s] ç”¨æˆ·å–æ¶ˆä½†å·²äº§ç”Ÿtokenè®¡è´¹", sp.requestID))
		} else {
			slog.Info(fmt.Sprintf("ğŸš« [æ—©æœŸå–æ¶ˆ] [%s] ç”¨æˆ·æ—©æœŸå–æ¶ˆï¼Œæœªäº§ç”Ÿè®¡è´¹", sp.requestID))
		}

		return "cancelled" // âœ… ä½¿ç”¨ç°æœ‰cancelledçŠ¶æ€
	}

	// å…¶ä»–é”™è¯¯ä¿æŒåŸæœ‰é€»è¾‘
	if strings.Contains(errStr, "timeout") || strings.Contains(errStr, "deadline exceeded") {
		return "timeout"
	}

	return "error"
}

// handlePartialStream å¤„ç†éƒ¨åˆ†æ•°æ®æµä¸­æ–­æƒ…å†µï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
// ğŸš« DEPRECATED: å·²è¢« handlePartialStreamV2() æ›¿ä»£ï¼Œæ­¤æ–¹æ³•å·²å®Œå…¨ç§»é™¤è¿è§„è°ƒç”¨
// å½“ç½‘ç»œä¸­æ–­æˆ–å…¶ä»–é”™è¯¯å‘ç”Ÿæ—¶ï¼Œä¸å†è¿›è¡Œé”™è¯¯åˆ†ç±»ï¼Œè®©ä¸Šå±‚ç»Ÿä¸€å¤„ç†
func (sp *StreamProcessor) handlePartialStream(err error) error {
	// âš ï¸ æ­¤æ–¹æ³•å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ handlePartialStreamV2() æ–¹æ³•
	// åŸå› ï¼šè¿åç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¶æ„ï¼Œç›´æ¥è°ƒç”¨ usageTracker è€Œéè¿”å›Tokenä¿¡æ¯

	// è®°å½•æµå¤„ç†ä¸­æ–­ä½†ä¸åšä»»ä½•usageTrackerè°ƒç”¨
	slog.Warn(fmt.Sprintf("âš ï¸ [æµå¼ä¸­æ–­] [%s] æµå¤„ç†ä¸­æ–­: %v, å·²å¤„ç† %d å­—èŠ‚. é”™è¯¯å°†ç”±ä¸Šå±‚ç»Ÿä¸€å¤„ç†.",
		sp.requestID, err, sp.bytesProcessed))

	// ç­‰å¾…æ‰€æœ‰åå°è§£æå®Œæˆ
	sp.waitForBackgroundParsing()

	// å°è¯•ä»éƒ¨åˆ†æ•°æ®ä¸­æ¢å¤æœ‰ç”¨ä¿¡æ¯
	if len(sp.partialData) > 0 {
		sp.errorRecovery.RecoverFromPartialData(sp.requestID, sp.partialData, time.Since(sp.startTime))
	}

	// ç›´æ¥è¿”å›é”™è¯¯ï¼Œè®©è°ƒç”¨è€…(handler)é€šè¿‡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¥åˆ†ç±»å’Œå¤„ç†æœ€ç»ˆå¤±è´¥
	return err
}

// ProcessStreamWithRetry æ”¯æŒç½‘ç»œä¸­æ–­æ¢å¤çš„æµå¼å¤„ç†ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
// åœ¨ç½‘ç»œä¸ç¨³å®šç¯å¢ƒä¸‹æä¾›æ™ºèƒ½é‡è¯•æœºåˆ¶
// è¿”å›å€¼ï¼š(finalTokenUsage *tracking.TokenUsage, modelName string, err error)
// ä¿®æ”¹ä¸ºè¿”å› Token ä½¿ç”¨ä¿¡æ¯å’Œæ¨¡å‹åç§°è€Œéç›´æ¥è®°å½•åˆ° usageTracker
func (sp *StreamProcessor) ProcessStreamWithRetry(ctx context.Context, resp *http.Response) (*tracking.TokenUsage, string, error) {
	const maxRetries = 3

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// åˆ†ç±»å½“å‰å°è¯•çš„é”™è¯¯ä¸Šä¸‹æ–‡
		var lastErr error

		if attempt > 0 {
			// ä½¿ç”¨é”™è¯¯æ¢å¤ç®¡ç†å™¨è®¡ç®—é‡è¯•å»¶è¿Ÿ
			errorCtx := sp.errorRecovery.ClassifyError(lastErr, sp.requestID, sp.endpoint, "", attempt)

			// æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
			if !sp.errorRecovery.ShouldRetry(errorCtx) {
				slog.Info(fmt.Sprintf("ğŸ›‘ [é‡è¯•åœæ­¢] [%s] é”™è¯¯æ¢å¤ç®¡ç†å™¨å»ºè®®åœæ­¢é‡è¯•", sp.requestID))
				sp.errorRecovery.HandleFinalFailure(errorCtx)
				return nil, "", lastErr
			}

			// æ‰§è¡Œé‡è¯•å»¶è¿Ÿ
			if retryErr := sp.errorRecovery.ExecuteRetry(ctx, errorCtx); retryErr != nil {
				return nil, "", retryErr
			}
		}

		// å°è¯•æµå¼å¤„ç†
		finalTokenUsage, err := sp.ProcessStream(ctx, resp)

		if err == nil {
			// âœ… æ£€æŸ¥æ˜¯å¦åœ¨å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°äº†APIé”™è¯¯
			if sp.lastAPIError != nil {
				// âœ… æµå¼å¤„ç†æˆåŠŸï¼Œä½†é‡åˆ°äº†APIé”™è¯¯ï¼ˆå¦‚SSEé”™è¯¯äº‹ä»¶ï¼‰
				// ä¿ç•™å·²è§£æçš„Tokenä¿¡æ¯è€Œä¸æ˜¯ä¸¢å¼ƒ
				modelName := sp.tokenParser.GetModelName()
				if modelName == "" {
					modelName = "unknown"
				}

				// âœ… æ™ºèƒ½é”™è¯¯åŒ…è£…ï¼šæ£€æŸ¥APIé”™è¯¯æ˜¯å¦å·²è¢«åŒ…è£…ï¼Œé¿å…é‡å¤åŒ…è£…
				if strings.HasPrefix(sp.lastAPIError.Error(), "stream_status:") {
					// å·²ç»æ˜¯åŒ…è£…åçš„é”™è¯¯ï¼Œç›´æ¥è¿”å›ï¼Œä¿æŒåŸå§‹çŠ¶æ€ä¿¡æ¯
					return finalTokenUsage, modelName, sp.lastAPIError
				} else {
					// åŸå§‹APIé”™è¯¯ï¼Œè¿›è¡ŒåŒ…è£…ä»¥ç¡®ä¿çŠ¶æ€ä¼ é€’
					// âœ… æ ¹æ®APIé”™è¯¯å†…å®¹æ™ºèƒ½ç¡®å®šçŠ¶æ€ï¼Œè€Œéç¡¬ç¼–ç 
					status := "stream_error" // é»˜è®¤æµé”™è¯¯çŠ¶æ€
					errorMsg := sp.lastAPIError.Error()
					if strings.Contains(errorMsg, "rate") || strings.Contains(errorMsg, "429") {
						status = "rate_limited"
					} else if strings.Contains(errorMsg, "timeout") || strings.Contains(errorMsg, "deadline") {
						status = "timeout"
					} else if strings.Contains(errorMsg, "cancel") {
						status = "cancelled"
					} else if strings.Contains(errorMsg, "auth") || strings.Contains(errorMsg, "401") {
						status = "auth_error"
					}

					wrappedErr := fmt.Errorf("stream_status:%s:model:%s: %w", status, modelName, sp.lastAPIError)
					return finalTokenUsage, modelName, wrappedErr
				}
			}

			// å¤„ç†æˆåŠŸï¼Œè·å–æ¨¡å‹åç§°
			modelName := sp.tokenParser.GetModelName()
			if modelName == "" {
				modelName = "default"
			}

			if attempt > 0 {
				slog.Info(fmt.Sprintf("âœ… [é‡è¯•æˆåŠŸ] [%s] ç¬¬ %d æ¬¡é‡è¯•æˆåŠŸ", sp.requestID, attempt))
			}
			return finalTokenUsage, modelName, nil
		}

		lastErr = err

		// ç®€åŒ–çš„é‡è¯•åˆ¤æ–­é€»è¾‘ï¼Œé¿å…é‡å¤é”™è¯¯åˆ†ç±»
		// å¯¹äºæµå¼å¤„ç†ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨ç½‘ç»œç›¸å…³çš„é”™è¯¯æ˜¯å¦å¯é‡è¯•
		shouldRetry := false
		if err != nil {
			errStr := strings.ToLower(err.Error())
			// ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºå¯é‡è¯•çš„ç½‘ç»œ/è¶…æ—¶é”™è¯¯
			if strings.Contains(errStr, "timeout") ||
				strings.Contains(errStr, "connection") ||
				strings.Contains(errStr, "network") ||
				strings.Contains(errStr, "reset") ||
				strings.Contains(errStr, "refused") {
				shouldRetry = true
			}
		}

		if shouldRetry && attempt < maxRetries {
			slog.Warn(fmt.Sprintf("ğŸ”„ [ç½‘ç»œé”™è¯¯é‡è¯•] [%s] ç½‘ç»œç›¸å…³é”™è¯¯å°†é‡è¯•: %v", sp.requestID, err))
			continue
		}

		// ä¸å¯é‡è¯•é”™è¯¯æˆ–é‡è¯•æ¬¡æ•°å·²æ»¡ï¼Œä¿ç•™é”™è¯¯åŒ…è£…å™¨ï¼Œç¡®ä¿çŠ¶æ€ä¼ é€’ï¼Œé¿å…é‡å¤åŒ…è£…
		slog.Info(fmt.Sprintf("ğŸ›‘ [é‡è¯•åœæ­¢] [%s] %d æ¬¡é‡è¯•ååœæ­¢ï¼Œé”™è¯¯å°†ç”±ä¸Šå±‚å¤„ç†: %v",
			sp.requestID, attempt, err))

		// âœ… è·å–å·²è§£æçš„Tokenä¿¡æ¯ï¼ˆä½†ä¸å¼ºåˆ¶è¿”å›ç©ºç»“æ„ä½“ï¼‰
		tokenUsage := sp.getFinalTokenUsage()
		modelName := sp.tokenParser.GetModelName()
		if modelName == "" {
			modelName = "unknown"
		}

		// âœ… æ™ºèƒ½é”™è¯¯åŒ…è£…ï¼šæ£€æŸ¥é”™è¯¯æ˜¯å¦å·²è¢«åŒ…è£…ï¼Œé¿å…é‡å¤åŒ…è£…
		if strings.HasPrefix(err.Error(), "stream_status:") {
			// å·²ç»æ˜¯åŒ…è£…åçš„é”™è¯¯ï¼Œç›´æ¥è¿”å›ï¼Œä¿æŒé”™è¯¯é“¾å®Œæ•´æ€§
			return tokenUsage, modelName, err
		} else {
			// åŸå§‹é”™è¯¯ï¼Œè¿›è¡ŒåŒ…è£…ä»¥ç¡®ä¿çŠ¶æ€ä¼ é€’
			// âœ… æ ¹æ®é”™è¯¯å†…å®¹æ™ºèƒ½ç¡®å®šçŠ¶æ€ï¼Œè€Œéç¡¬ç¼–ç ä¸º"error"
			status := "error" // é»˜è®¤çŠ¶æ€
			if strings.Contains(err.Error(), "timeout") || strings.Contains(err.Error(), "deadline") {
				status = "timeout"
			} else if strings.Contains(err.Error(), "cancel") {
				status = "cancelled"
			} else if strings.Contains(err.Error(), "network") || strings.Contains(err.Error(), "connection") {
				status = "network_error"
			}

			wrappedErr := fmt.Errorf("stream_status:%s:model:%s: %w", status, modelName, err)
			return tokenUsage, modelName, wrappedErr
		}
	}

	// åˆ›å»ºæœ€ç»ˆå¤±è´¥çš„é”™è¯¯ä¸Šä¸‹æ–‡
	finalErrorCtx := &ErrorContext{
		RequestID:     sp.requestID,
		EndpointName:  sp.endpoint,
		AttemptCount:  maxRetries,
		ErrorType:     ErrorTypeUnknown,
		OriginalError: fmt.Errorf("stream processing failed after %d retries", maxRetries),
	}
	sp.errorRecovery.HandleFinalFailure(finalErrorCtx)

	return nil, "", fmt.Errorf("stream processing failed after %d retries", maxRetries)
}

// waitForBackgroundParsing ç­‰å¾…æ‰€æœ‰åå°è§£æå®Œæˆ
func (sp *StreamProcessor) waitForBackgroundParsing() {
	// ç­‰å¾…æ‰€æœ‰åå°goroutineå®Œæˆ
	sp.parseWg.Wait()

	// å¤„ç†å‰©ä½™çš„è¡Œç¼“å†²åŒºæ•°æ®
	sp.parseMutex.Lock()
	if len(sp.lineBuffer) > 0 {
		line := strings.TrimSpace(string(sp.lineBuffer))
		if len(line) > 0 {
			sp.processSSELine(line)
		}
		sp.lineBuffer = sp.lineBuffer[:0]
	}

	// âœ… å¼ºåˆ¶åˆ·æ–°ç¼“å­˜çš„å¾…å¤„ç†äº‹ä»¶
	// ç¡®ä¿å³ä½¿ä¸Šæ¸¸æ²¡æœ‰å‘é€ç»ˆæ­¢ç©ºè¡Œï¼Œä¹Ÿèƒ½è§£æå®Œæ•´çš„ usage ä¿¡æ¯
	if result := sp.tokenParser.FlushPendingEvent(); result != nil {
		// å¤„ç†åˆ·æ–°åçš„è§£æç»“æœ
		if result.ErrorInfo != nil {
			slog.Error(fmt.Sprintf("âŒ [Flushé”™è¯¯] [%s] ç±»å‹: %s, æ¶ˆæ¯: %s",
				sp.requestID, result.ErrorInfo.Type, result.ErrorInfo.Message))
			sp.lastAPIError = fmt.Errorf("APIé”™è¯¯ %s: %s", result.ErrorInfo.Type, result.ErrorInfo.Message)
		} else if result.TokenUsage != nil {
			slog.Debug(fmt.Sprintf("ğŸ”„ [FlushæˆåŠŸ] [%s] æˆåŠŸè§£æå¾…å¤„ç†äº‹ä»¶çš„Tokenä¿¡æ¯", sp.requestID))
		}
	}

	sp.parseMutex.Unlock()
}

// savePartialData ä¿å­˜éƒ¨åˆ†æ•°æ®ç”¨äºé”™è¯¯æ¢å¤
func (sp *StreamProcessor) savePartialData(chunk []byte) {
	// é™åˆ¶éƒ¨åˆ†æ•°æ®ç¼“å†²åŒºå¤§å°ï¼Œé˜²æ­¢å†…å­˜è¿‡åº¦ä½¿ç”¨
	const maxPartialDataSize = 64 * 1024 // 64KB

	sp.parseMutex.Lock()
	defer sp.parseMutex.Unlock()

	// å¦‚æœæ·»åŠ æ–°æ•°æ®ä¼šè¶…è¿‡é™åˆ¶ï¼Œåˆ™ç§»é™¤æ—§æ•°æ®
	if len(sp.partialData)+len(chunk) > maxPartialDataSize {
		// ä¿ç•™æœ€åçš„32KBæ•°æ®ï¼Œä¸¢å¼ƒæ›´æ—©çš„æ•°æ®
		keepSize := maxPartialDataSize/2 - len(chunk)
		if keepSize > 0 && keepSize < len(sp.partialData) {
			copy(sp.partialData, sp.partialData[len(sp.partialData)-keepSize:])
			sp.partialData = sp.partialData[:keepSize]
		} else {
			sp.partialData = sp.partialData[:0]
		}
	}

	// æ·»åŠ æ–°çš„æ•°æ®å—
	sp.partialData = append(sp.partialData, chunk...)
}

// GetProcessingStats è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
func (sp *StreamProcessor) GetProcessingStats() map[string]interface{} {
	return map[string]interface{}{
		"request_id":       sp.requestID,
		"endpoint":         sp.endpoint,
		"bytes_processed":  sp.bytesProcessed,
		"processing_time":  time.Since(sp.startTime),
		"parse_errors":     len(sp.parseErrors),
		"max_parse_errors": sp.maxParseErrors,
	}
}

// Reset é‡ç½®å¤„ç†å™¨çŠ¶æ€ï¼Œç”¨äºå¤ç”¨
func (sp *StreamProcessor) Reset() {
	sp.parseMutex.Lock()
	defer sp.parseMutex.Unlock()

	sp.startTime = time.Now()
	sp.bytesProcessed = 0
	sp.lineBuffer = sp.lineBuffer[:0]
	sp.partialData = sp.partialData[:0] // é‡ç½®éƒ¨åˆ†æ•°æ®ç¼“å†²åŒº
	sp.parseErrors = sp.parseErrors[:0]

	// é‡ç½®TokenParserçŠ¶æ€
	if sp.tokenParser != nil {
		sp.tokenParser.Reset()
	}

	slog.Info(fmt.Sprintf("ğŸ”„ [å¤„ç†å™¨é‡ç½®] [%s] æµå¤„ç†å™¨å·²é‡ç½®", sp.requestID))
}

// handleCancellation å¤„ç†å®¢æˆ·ç«¯å–æ¶ˆè¯·æ±‚ - Phase 2 ä¼˜é›…å–æ¶ˆå¤„ç†å™¨
// ğŸš« DEPRECATED: å·²è¢« handleCancellationV2() æ›¿ä»£ï¼Œä¸å†ç›´æ¥è°ƒç”¨ usageTracker
func (sp *StreamProcessor) handleCancellation(ctx context.Context, cancelErr error) error {
	// âš ï¸ æ­¤æ–¹æ³•å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ handleCancellationV2() æ–¹æ³•
	// åŸå› ï¼šè¿åç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¶æ„ï¼Œé€šè¿‡ collectAvailableInfo é—´æ¥è°ƒç”¨ usageTracker

	slog.Info(fmt.Sprintf("ğŸš« [å®¢æˆ·ç«¯å–æ¶ˆ] [%s] æ£€æµ‹åˆ°å®¢æˆ·ç«¯å–æ¶ˆ: %v", sp.requestID, cancelErr))

	// ç­‰å¾…åå°è§£æå®Œæˆï¼Œä½†ä¸è¶…è¿‡è¶…æ—¶æ—¶é—´
	if finished := sp.waitForParsingWithTimeout(2 * time.Second); finished {
		// æˆåŠŸç­‰å¾…è§£æå®Œæˆï¼Œè°ƒç”¨æ–°ç‰ˆæœ¬æ–¹æ³•è·å–Tokenä¿¡æ¯
		tokenUsage, err := sp.collectAvailableInfoV2(cancelErr, "cancelled_with_data")
		_ = tokenUsage // å¿½ç•¥Tokenä¿¡æ¯ï¼Œä¿æŒåŸæ¥å£å…¼å®¹
		return err
	} else {
		// è¶…æ—¶æœªå®Œæˆï¼Œè°ƒç”¨æ–°ç‰ˆæœ¬æ–¹æ³•è·å–Tokenä¿¡æ¯
		tokenUsage, err := sp.collectAvailableInfoV2(cancelErr, "cancelled_timeout")
		_ = tokenUsage // å¿½ç•¥Tokenä¿¡æ¯ï¼Œä¿æŒåŸæ¥å£å…¼å®¹
		return err
	}
}

// waitForParsingWithTimeout å¸¦è¶…æ—¶çš„ç­‰å¾…è§£æå®Œæˆ - Phase 2 è¶…æ—¶ç­‰å¾…æœºåˆ¶
func (sp *StreamProcessor) waitForParsingWithTimeout(timeout time.Duration) bool {
	done := make(chan struct{})

	go func() {
		sp.parseWg.Wait()
		close(done)
	}()

	select {
	case <-done:
		slog.Info(fmt.Sprintf("âœ… [è§£æå®Œæˆ] [%s] åå°è§£æåœ¨å–æ¶ˆå‰å®Œæˆ", sp.requestID))
		return true
	case <-time.After(timeout):
		slog.Warn(fmt.Sprintf("â° [è§£æè¶…æ—¶] [%s] åå°è§£æåœ¨ %v å†…æœªå®Œæˆ", sp.requestID, timeout))
		return false
	}
}

// collectAvailableInfo æ™ºèƒ½ä¿¡æ¯æ”¶é›† - Phase 2 åˆ†é˜¶æ®µä¿å­˜é€»è¾‘
// ğŸš« DEPRECATED: å·²è¢« collectAvailableInfoV2() æ›¿ä»£ï¼Œæ­¤æ–¹æ³•å·²å®Œå…¨ç§»é™¤è¿è§„è°ƒç”¨
func (sp *StreamProcessor) collectAvailableInfo(cancelErr error, status string) error {
	// âš ï¸ æ­¤æ–¹æ³•å·²å®Œå…¨å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ collectAvailableInfoV2() æ–¹æ³•
	// åŸå› ï¼šè¿åç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¶æ„ï¼Œç›´æ¥è°ƒç”¨ usageTracker è€Œéè¿”å›Tokenä¿¡æ¯
	//
	// æ–°çš„æ¶æ„è¦æ±‚ï¼š
	// 1. StreamProcessor åªè´Ÿè´£æ”¶é›†Tokenä¿¡æ¯
	// 2. Handler è°ƒç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•çŠ¶æ€
	// 3. ä¸å†æœ‰ä»»ä½•ç»„ä»¶ç›´æ¥è°ƒç”¨ usageTracker

	slog.Debug(fmt.Sprintf("âš ï¸ [å·²å¼ƒç”¨] [%s] collectAvailableInfoå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨collectAvailableInfoV2", sp.requestID))
	return cancelErr
}

// getFinalTokenUsage è·å–æœ€ç»ˆçš„Tokenä½¿ç”¨ä¿¡æ¯ï¼ˆä¿®å¤ç‰ˆï¼‰
func (sp *StreamProcessor) getFinalTokenUsage() *tracking.TokenUsage {
	sp.parseMutex.Lock()
	defer sp.parseMutex.Unlock()

	// å°è¯•ä»TokenParserè·å–æœ€ç»ˆä½¿ç”¨ç»Ÿè®¡
	finalUsage := sp.tokenParser.GetFinalUsage()

	// ğŸ” [Fallbackæ£€æµ‹] æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†fallbackæœºåˆ¶
	if sp.tokenParser.IsFallbackUsed() {
		slog.Warn(fmt.Sprintf("ğŸš¨ [Fallbackæ£€æµ‹] [%s] ä½¿ç”¨äº†message_start fallbackæœºåˆ¶ï¼Œä¿å­˜å®Œæ•´è°ƒè¯•æ•°æ®", sp.requestID))

		// ğŸ”§ [Fallbackä¿®å¤] fallbackæ—¶ä½¿ç”¨å®Œæ•´çš„å“åº”æ•°æ®ï¼Œä¸å—100è¡Œé™åˆ¶
		if len(sp.partialData) > 0 {
			// å°†å®Œæ•´çš„åŸå§‹æ•°æ®æŒ‰è¡Œåˆ†å‰²
			fullLines := strings.Split(string(sp.partialData), "\n")
			slog.Info(fmt.Sprintf("ğŸ”§ [å®Œæ•´æ•°æ®] [%s] ä½¿ç”¨%då­—èŠ‚å®Œæ•´æ•°æ®æ›¿ä»£100è¡Œé™åˆ¶æ•°æ®", sp.requestID, len(sp.partialData)))

			// ä½¿ç”¨å®Œæ•´æ•°æ®ä¿å­˜debugæ–‡ä»¶
			utils.WriteStreamDebugResponse(sp.requestID, sp.endpoint, fullLines, sp.bytesProcessed)
		} else {
			// å…œåº•ï¼šå¦‚æœæ²¡æœ‰å®Œæ•´æ•°æ®ï¼Œä½¿ç”¨ç°æœ‰çš„debugæ•°æ®
			utils.WriteStreamDebugResponse(sp.requestID, sp.endpoint, sp.debugLines, sp.bytesProcessed)
		}

		// ğŸ”§ [Fallbackä¿®å¤] å¼‚æ­¥å°è¯•ä»debugæ–‡ä»¶æ¢å¤å®Œæ•´çš„usageä¿¡æ¯
		go sp.attemptUsageRecovery()
	}

	if finalUsage != nil {
		// âœ… æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„Tokenä½¿ç”¨
		hasRealTokens := finalUsage.InputTokens > 0 || finalUsage.OutputTokens > 0 ||
			finalUsage.CacheCreationTokens > 0 || finalUsage.CacheReadTokens > 0

		if hasRealTokens {
			// æœ‰çœŸå®tokenä¿¡æ¯ï¼Œè®°å½•è¯¦ç»†æ—¥å¿—
			modelName := sp.tokenParser.GetModelName()
			if modelName == "" {
				modelName = "default"
			}
			slog.Info(fmt.Sprintf("ğŸª™ [Tokenæœ€ç»ˆç»Ÿè®¡] [%s] æµå¼å¤„ç†å®Œæˆ - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d",
				sp.requestID, modelName, finalUsage.InputTokens, finalUsage.OutputTokens, finalUsage.CacheCreationTokens, finalUsage.CacheReadTokens))
			return finalUsage
		} else {
			// æœ‰finalUsageç»“æ„ä½†æ— å®é™…tokenï¼Œè¿”å›nil
			slog.Info(fmt.Sprintf("ğŸ¯ [æ— Tokenå®Œæˆ] [%s] æµå¼å“åº”åŒ…å«ç©ºTokenä¿¡æ¯", sp.requestID))

			// ğŸ” [è°ƒè¯•] å¼‚æ­¥ä¿å­˜æµå¼è°ƒè¯•æ•°æ®ç”¨äºåˆ†æTokenè§£æå¤±è´¥
			utils.WriteStreamDebugResponse(sp.requestID, sp.endpoint, sp.debugLines, sp.bytesProcessed)

			return nil
		}
	} else {
		// æ²¡æœ‰tokenä¿¡æ¯ï¼Œè¿”å›nil
		slog.Info(fmt.Sprintf("ğŸ¯ [æ— Tokenå®Œæˆ] [%s] æµå¼å“åº”ä¸åŒ…å«tokenä¿¡æ¯", sp.requestID))

		// ğŸ” [è°ƒè¯•] å¼‚æ­¥ä¿å­˜æµå¼è°ƒè¯•æ•°æ®ç”¨äºåˆ†æTokenè§£æå¤±è´¥
		utils.WriteStreamDebugResponse(sp.requestID, sp.endpoint, sp.debugLines, sp.bytesProcessed)

		return nil
	}
}

// handlePartialStreamV2 å¤„ç†éƒ¨åˆ†æ•°æ®æµä¸­æ–­æƒ…å†µï¼ˆè¿”å›Tokenä¿¡æ¯ç‰ˆæœ¬ï¼‰
// å½“ç½‘ç»œä¸­æ–­æˆ–å…¶ä»–é”™è¯¯å‘ç”Ÿæ—¶ï¼Œæ”¶é›†å·²è§£æçš„Tokenä¿¡æ¯å¹¶è¿”å›
func (sp *StreamProcessor) handlePartialStreamV2(err error) (*tracking.TokenUsage, error) {
	// âœ… ç­‰å¾…æ‰€æœ‰åå°è§£æå®Œæˆï¼ˆåŒ…å«flushé€»è¾‘ï¼‰
	sp.waitForBackgroundParsing()

	// è·å–Tokenä¿¡æ¯å’Œæ¨¡å‹åç§°
	finalUsage := sp.tokenParser.GetFinalUsage()
	modelName := sp.tokenParser.GetModelName()
	if modelName == "" {
		modelName = "unknown"
	}

	// âœ… ä½¿ç”¨æ™ºèƒ½çŠ¶æ€åˆ†ç±»
	status := sp.classifyStreamError(err, finalUsage)

	if finalUsage != nil {
		slog.Info(fmt.Sprintf("ğŸ’¾ [æµä¸­æ–­ä¿å­˜] [%s] çŠ¶æ€: %s, æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜: %d+%d",
			sp.requestID, status, modelName, finalUsage.InputTokens, finalUsage.OutputTokens,
			finalUsage.CacheCreationTokens, finalUsage.CacheReadTokens))
	} else {
		slog.Info(fmt.Sprintf("ğŸ’¾ [æµä¸­æ–­ä¿å­˜] [%s] çŠ¶æ€: %s, æ¨¡å‹: %s, æ— tokenä¿¡æ¯",
			sp.requestID, status, modelName))
	}

	// å°è¯•ä»éƒ¨åˆ†æ•°æ®ä¸­æ¢å¤æœ‰ç”¨ä¿¡æ¯
	if len(sp.partialData) > 0 {
		sp.errorRecovery.RecoverFromPartialData(sp.requestID, sp.partialData, time.Since(sp.startTime))
	}

	// å¤„ç†Tokenä¿¡æ¯
	var partialTokenUsage *tracking.TokenUsage
	if finalUsage != nil {
		partialTokenUsage = finalUsage
	} else {
		partialTokenUsage = &tracking.TokenUsage{
			InputTokens: 0, OutputTokens: 0,
			CacheCreationTokens: 0, CacheReadTokens: 0,
		}
	}

	// âœ… è¿”å›åŒ…å«çŠ¶æ€å’Œæ¨¡å‹ä¿¡æ¯çš„é”™è¯¯ï¼Œä¾›ä¸Šå±‚å¤„ç†
	return partialTokenUsage, fmt.Errorf("stream_status:%s:model:%s: %w", status, modelName, err)
}

// handleCancellationV2 å¤„ç†å®¢æˆ·ç«¯å–æ¶ˆè¯·æ±‚ï¼ˆè¿”å›Tokenä¿¡æ¯ç‰ˆæœ¬ï¼‰
func (sp *StreamProcessor) handleCancellationV2(ctx context.Context, cancelErr error) (*tracking.TokenUsage, error) {
	slog.Info(fmt.Sprintf("ğŸš« [å®¢æˆ·ç«¯å–æ¶ˆ] [%s] æ£€æµ‹åˆ°å®¢æˆ·ç«¯å–æ¶ˆ: %v", sp.requestID, cancelErr))

	// ç­‰å¾…åå°è§£æå®Œæˆï¼Œä½†ä¸è¶…è¿‡è¶…æ—¶æ—¶é—´
	if finished := sp.waitForParsingWithTimeout(2 * time.Second); finished {
		// æˆåŠŸç­‰å¾…è§£æå®Œæˆï¼Œæ”¶é›†å¯ç”¨ä¿¡æ¯
		return sp.collectAvailableInfoV2(cancelErr, "cancelled_with_data")
	} else {
		// è¶…æ—¶æœªå®Œæˆï¼Œæ”¶é›†éƒ¨åˆ†ä¿¡æ¯
		return sp.collectAvailableInfoV2(cancelErr, "cancelled_timeout")
	}
}

// collectAvailableInfoV2 æ™ºèƒ½ä¿¡æ¯æ”¶é›†ï¼ˆè¿”å›Tokenä¿¡æ¯ç‰ˆæœ¬ï¼‰
func (sp *StreamProcessor) collectAvailableInfoV2(cancelErr error, status string) (*tracking.TokenUsage, error) {
	sp.parseMutex.Lock()
	defer sp.parseMutex.Unlock()

	// âœ… å°è¯•åˆ·æ–°å¾…å¤„ç†äº‹ä»¶
	if result := sp.tokenParser.FlushPendingEvent(); result != nil {
		if result.ErrorInfo != nil {
			slog.Error(fmt.Sprintf("âŒ [å–æ¶ˆFlushé”™è¯¯] [%s] ç±»å‹: %s, æ¶ˆæ¯: %s",
				sp.requestID, result.ErrorInfo.Type, result.ErrorInfo.Message))
		} else if result.TokenUsage != nil {
			slog.Debug(fmt.Sprintf("ğŸ”„ [å–æ¶ˆFlushæˆåŠŸ] [%s] æˆåŠŸè§£æå–æ¶ˆå‰çš„å¾…å¤„ç†äº‹ä»¶", sp.requestID))
		}
	}

	// è·å–å·²è§£æçš„ä¿¡æ¯
	modelName := sp.tokenParser.GetModelName()
	finalUsage := sp.tokenParser.GetFinalUsage()

	// âœ… ä½¿ç”¨æ™ºèƒ½çŠ¶æ€åˆ†ç±»
	statusClassified := sp.classifyStreamError(cancelErr, finalUsage)

	var tokenUsage *tracking.TokenUsage

	if finalUsage != nil {
		tokenUsage = finalUsage
		slog.Info(fmt.Sprintf("ğŸ’¾ [å–æ¶ˆä¿å­˜] [%s] çŠ¶æ€: %s, æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d",
			sp.requestID, statusClassified, modelName, finalUsage.InputTokens, finalUsage.OutputTokens))
	} else {
		tokenUsage = &tracking.TokenUsage{
			InputTokens: 0, OutputTokens: 0,
			CacheCreationTokens: 0, CacheReadTokens: 0,
		}
		slog.Info(fmt.Sprintf("ğŸ’¾ [å–æ¶ˆä¿å­˜] [%s] çŠ¶æ€: %s, æ¨¡å‹: %s, æ— tokenä¿¡æ¯",
			sp.requestID, statusClassified, modelName))
	}

	// âœ… è¿”å›åŒ…å«å®Œæ•´ä¿¡æ¯çš„é”™è¯¯
	return tokenUsage, fmt.Errorf("stream_status:%s:model:%s: %w", statusClassified, modelName, cancelErr)
}
