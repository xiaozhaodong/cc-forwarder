package proxy

import (
	"bytes"
	"compress/flate"
	"compress/gzip"
	"compress/lzw"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log/slog"
	"math"
	"net/http"
	"net/url"
	"strings"
	"time"

	"cc-forwarder/config"
	"cc-forwarder/internal/endpoint"
	"cc-forwarder/internal/monitor"
	"cc-forwarder/internal/tracking"
	"cc-forwarder/internal/transport"
	"github.com/andybalholm/brotli"
)

// Context key for endpoint information
type contextKey string

const EndpointContextKey = contextKey("endpoint")

// Handler handles HTTP proxy requests
type Handler struct {
	endpointManager *endpoint.Manager
	config          *config.Config
	retryHandler    *RetryHandler
	usageTracker    *tracking.UsageTracker
}

// NewHandler creates a new proxy handler
func NewHandler(endpointManager *endpoint.Manager, cfg *config.Config) *Handler {
	retryHandler := NewRetryHandler(cfg)
	retryHandler.SetEndpointManager(endpointManager)
	
	return &Handler{
		endpointManager: endpointManager,
		config:          cfg,
		retryHandler:    retryHandler,
	}
}

// SetMonitoringMiddleware sets the monitoring middleware for retry tracking
func (h *Handler) SetMonitoringMiddleware(mm interface{
	RecordRetry(connID string, endpoint string)
}) {
	h.retryHandler.SetMonitoringMiddleware(mm)
}

// SetUsageTracker sets the usage tracker for request tracking
func (h *Handler) SetUsageTracker(ut *tracking.UsageTracker) {
	h.usageTracker = ut
}

// GetRetryHandler returns the retry handler for accessing suspended request counts
func (h *Handler) GetRetryHandler() *RetryHandler {
	return h.retryHandler
}

// ServeHTTP implements the http.Handler interface
// ç»Ÿä¸€è¯·æ±‚åˆ†å‘é€»è¾‘ - æ•´åˆæµå¼å¤„ç†ã€é”™è¯¯æ¢å¤å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†
func (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	// åˆ›å»ºè¯·æ±‚ä¸Šä¸‹æ–‡
	ctx := r.Context()
	
	// è·å–è¿æ¥ID
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// åˆ›å»ºç»Ÿä¸€çš„è¯·æ±‚ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
	lifecycleManager := NewRequestLifecycleManager(h.usageTracker, connID)
	
	// å¼€å§‹è¯·æ±‚è·Ÿè¸ª
	clientIP := r.RemoteAddr
	userAgent := r.Header.Get("User-Agent")
	lifecycleManager.StartRequest(clientIP, userAgent)
	
	// å…‹éš†è¯·æ±‚ä½“ç”¨äºé‡è¯•
	var bodyBytes []byte
	if r.Body != nil {
		var err error
		bodyBytes, err = io.ReadAll(r.Body)
		if err != nil {
			lifecycleManager.HandleError(err)
			http.Error(w, "Failed to read request body", http.StatusInternalServerError)
			return
		}
		r.Body.Close()
	}

	// æ£€æµ‹æ˜¯å¦ä¸ºSSEæµå¼è¯·æ±‚
	isSSE := h.detectSSERequest(r, bodyBytes)
	
	// ç»Ÿä¸€è¯·æ±‚å¤„ç†
	if isSSE {
		// æµå¼è¯·æ±‚å¤„ç†
		h.handleStreamingRequest(ctx, w, r, bodyBytes, lifecycleManager)
	} else {
		// å¸¸è§„è¯·æ±‚å¤„ç†
		h.handleRegularRequestUnified(ctx, w, r, bodyBytes, lifecycleManager)
	}
}

// detectSSERequest ç»Ÿä¸€SSEè¯·æ±‚æ£€æµ‹é€»è¾‘
func (h *Handler) detectSSERequest(r *http.Request, bodyBytes []byte) bool {
	// æ£€æŸ¥å¤šç§SSEè¯·æ±‚æ¨¡å¼:
	acceptHeader := r.Header.Get("Accept")
	cacheControlHeader := r.Header.Get("Cache-Control")
	streamHeader := r.Header.Get("stream")
	
	// 1. Acceptå¤´åŒ…å«text/event-stream
	if strings.Contains(acceptHeader, "text/event-stream") {
		return true
	}
	
	// 2. Cache-Controlå¤´åŒ…å«no-cache (å¸¸è§äºSSE)
	if strings.Contains(cacheControlHeader, "no-cache") {
		return true
	}
	
	// 3. streamå¤´è®¾ç½®ä¸ºtrue
	if streamHeader == "true" {
		return true
	}
	
	// 4. è¯·æ±‚ä½“åŒ…å«streamå‚æ•°ä¸ºtrue
	bodyStr := string(bodyBytes)
	if strings.Contains(bodyStr, `"stream":true`) || strings.Contains(bodyStr, `"stream": true`) {
		return true
	}
	
	return false
}

// handleStreamingRequest ç»Ÿä¸€æµå¼è¯·æ±‚å¤„ç†
// ä½¿ç”¨V2æ¶æ„æ•´åˆé”™è¯¯æ¢å¤æœºåˆ¶å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†çš„æµå¼å¤„ç†
func (h *Handler) handleStreamingRequest(ctx context.Context, w http.ResponseWriter, r *http.Request, bodyBytes []byte, lifecycleManager *RequestLifecycleManager) {
	connID := lifecycleManager.GetRequestID()
	
	slog.Info(fmt.Sprintf("ğŸŒŠ [æµå¼æ¶æ„] [%s] ä½¿ç”¨streaming v2æ¶æ„", connID))
	slog.Info(fmt.Sprintf("ğŸŒŠ [æµå¼å¤„ç†] [%s] å¼€å§‹æµå¼è¯·æ±‚å¤„ç†", connID))
	h.handleStreamingV2(ctx, w, r, bodyBytes, lifecycleManager)
}

// handleStreamingV2 æµå¼å¤„ç†ï¼ˆå¸¦é”™è¯¯æ¢å¤ï¼‰
func (h *Handler) handleStreamingV2(ctx context.Context, w http.ResponseWriter, r *http.Request, bodyBytes []byte, lifecycleManager *RequestLifecycleManager) {
	connID := lifecycleManager.GetRequestID()
	
	// è®¾ç½®æµå¼å“åº”å¤´
	h.setStreamingHeaders(w)
	
	// è·å–Flusher - å¦‚æœä¸æ”¯æŒï¼Œä½¿ç”¨æ— flushæ¨¡å¼ç»§ç»­æµå¼å¤„ç†
	flusher, ok := w.(http.Flusher)
	if !ok {
		slog.Warn(fmt.Sprintf("ğŸŒŠ [Flusherä¸æ”¯æŒ] [%s] å°†ä½¿ç”¨æ— flushæ¨¡å¼çš„æµå¼å¤„ç†", connID))
		// åˆ›å»ºä¸€ä¸ªmock flusherï¼Œä¸æ‰§è¡Œå®é™…flushæ“ä½œ
		flusher = &noOpFlusher{}
	}
	
	// ç»§ç»­æ‰§è¡Œæµå¼è¯·æ±‚å¤„ç†
	h.executeStreamingWithRetry(ctx, w, r, bodyBytes, lifecycleManager, flusher)
}

// noOpFlusher æ˜¯ä¸€ä¸ªä¸æ‰§è¡Œå®é™…flushæ“ä½œçš„flusherå®ç°
type noOpFlusher struct{}

func (f *noOpFlusher) Flush() {
	// ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼Œé¿å…panicä½†ä¿æŒæµå¼å¤„ç†é€»è¾‘
}


// setStreamingHeaders è®¾ç½®æµå¼å“åº”å¤´
func (h *Handler) setStreamingHeaders(w http.ResponseWriter) {
	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("Transfer-Encoding", "chunked")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Headers", "Cache-Control")
}

// executeStreamingWithRetry æ‰§è¡Œå¸¦é‡è¯•çš„æµå¼å¤„ç†
func (h *Handler) executeStreamingWithRetry(ctx context.Context, w http.ResponseWriter, r *http.Request, bodyBytes []byte, lifecycleManager *RequestLifecycleManager, flusher http.Flusher) {
	connID := lifecycleManager.GetRequestID()
	
	// è·å–å¥åº·ç«¯ç‚¹
	var endpoints []*endpoint.Endpoint
	if h.endpointManager.GetConfig().Strategy.Type == "fastest" && h.endpointManager.GetConfig().Strategy.FastTestEnabled {
		endpoints = h.endpointManager.GetFastestEndpointsWithRealTimeTest(ctx)
	} else {
		endpoints = h.endpointManager.GetHealthyEndpoints()
	}
	
	if len(endpoints) == 0 {
		lifecycleManager.HandleError(fmt.Errorf("no healthy endpoints available"))
		w.WriteHeader(http.StatusServiceUnavailable)
		fmt.Fprintf(w, "data: error: No healthy endpoints available\n\n")
		flusher.Flush()
		return
	}
	
	slog.Info(fmt.Sprintf("ğŸŒŠ [æµå¼å¼€å§‹] [%s] æµå¼è¯·æ±‚å¼€å§‹ï¼Œç«¯ç‚¹æ•°: %d", connID, len(endpoints)))
	
	// ğŸ”§ [é‡è¯•é€»è¾‘ä¿®å¤] å¯¹æ¯ä¸ªç«¯ç‚¹è¿›è¡Œmax_attemptsæ¬¡é‡è¯•ï¼Œè€Œä¸æ˜¯åªå°è¯•ä¸€æ¬¡
	// å°è¯•ç«¯ç‚¹ç›´åˆ°æˆåŠŸ
	var lastErr error  // å£°æ˜åœ¨å¤–å±‚ä½œç”¨åŸŸï¼Œä¾›æœ€ç»ˆé”™è¯¯å¤„ç†ä½¿ç”¨
	for i := 0; i < len(endpoints); i++ {
		ep := endpoints[i]
		// æ›´æ–°ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ä¿¡æ¯
		lifecycleManager.SetEndpoint(ep.Config.Name, ep.Config.Group)
		lifecycleManager.UpdateStatus("forwarding", i, 0)
		
		// âœ… [åŒç«¯ç‚¹é‡è¯•] å¯¹å½“å‰ç«¯ç‚¹è¿›è¡Œmax_attemptsæ¬¡é‡è¯•
		endpointSuccess := false
		
		for attempt := 1; attempt <= h.config.Retry.MaxAttempts; attempt++ {
			// æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
			select {
			case <-ctx.Done():
				slog.Info(fmt.Sprintf("ğŸš« [å®¢æˆ·ç«¯å–æ¶ˆæ£€æµ‹] [%s] æ£€æµ‹åˆ°å®¢æˆ·ç«¯å–æ¶ˆï¼Œç«‹å³åœæ­¢é‡è¯•", connID))
				lifecycleManager.UpdateStatus("cancelled", i+1, attempt-1)
				fmt.Fprintf(w, "data: cancelled: å®¢æˆ·ç«¯å–æ¶ˆè¯·æ±‚\n\n")
				flusher.Flush()
				return
			default:
			}
			
			// å°è¯•è¿æ¥ç«¯ç‚¹
			resp, err := h.forwardRequestToEndpoint(ctx, r, bodyBytes, ep)
			if err == nil {
				// âœ… æˆåŠŸï¼å¼€å§‹å¤„ç†å“åº”
				endpointSuccess = true
				slog.Info(fmt.Sprintf("âœ… [æµå¼æˆåŠŸ] [%s] ç«¯ç‚¹: %s (ç»„: %s), å°è¯•æ¬¡æ•°: %d", 
					connID, ep.Config.Name, ep.Config.Group, attempt))
					
				lifecycleManager.UpdateStatus("processing", i+1, attempt)
				
				// å¤„ç†æµå¼å“åº” - ä½¿ç”¨ç°æœ‰çš„æµå¼å¤„ç†é€»è¾‘
				w.WriteHeader(resp.StatusCode)
				
				// åˆ›å»ºTokenè§£æå™¨å’Œæµå¼å¤„ç†å™¨
				tokenParser := NewTokenParserWithUsageTracker(connID, h.usageTracker)
				processor := NewStreamProcessor(tokenParser, h.usageTracker, w, flusher, connID, ep.Config.Name)
				
				slog.Info(fmt.Sprintf("ğŸš€ [å¼€å§‹æµå¼å¤„ç†] [%s] ç«¯ç‚¹: %s", connID, ep.Config.Name))
				
				// æ‰§è¡Œæµå¼å¤„ç†
				if err := processor.ProcessStreamWithRetry(ctx, resp); err != nil {
					slog.Warn(fmt.Sprintf("ğŸ”„ [æµå¼å¤„ç†å¤±è´¥] [%s] ç«¯ç‚¹: %s, é”™è¯¯: %v", 
						connID, ep.Config.Name, err))
					
					// æµå¼å¤„ç†å¤±è´¥ï¼Œä½†HTTPè¿æ¥å·²æˆåŠŸå»ºç«‹ï¼Œè®°å½•ä¸ºprocessingçŠ¶æ€
					lifecycleManager.UpdateStatus("error", i+1, resp.StatusCode)
					fmt.Fprintf(w, "data: error: æµå¼å¤„ç†å¤±è´¥: %v\n\n", err)
					flusher.Flush()
					return
				}
				
				// å¤„ç†æˆåŠŸå®Œæˆ
				lifecycleManager.UpdateStatus("completed", i+1, resp.StatusCode)
				return
			}
			
			// âŒ å‡ºç°é”™è¯¯ï¼Œè¿›è¡Œé”™è¯¯åˆ†ç±»
			lastErr = err
			errorRecovery := NewErrorRecoveryManager(h.usageTracker)
			errorCtx := errorRecovery.ClassifyError(err, connID, ep.Config.Name, ep.Config.Group, attempt-1)
			
			// æ£€æŸ¥æ˜¯å¦ä¸ºå®¢æˆ·ç«¯å–æ¶ˆé”™è¯¯
			if errorCtx.ErrorType == ErrorTypeClientCancel {
				slog.Info(fmt.Sprintf("ğŸš« [å®¢æˆ·ç«¯å–æ¶ˆæ£€æµ‹] [%s] æ£€æµ‹åˆ°å®¢æˆ·ç«¯å–æ¶ˆï¼Œç«‹å³åœæ­¢é‡è¯•", connID))
				lifecycleManager.UpdateStatus("cancelled", i+1, attempt-1)
				fmt.Fprintf(w, "data: cancelled: å®¢æˆ·ç«¯å–æ¶ˆè¯·æ±‚\n\n")
				flusher.Flush()
				return
			}
			
			// éå–æ¶ˆé”™è¯¯ï¼šè®°å½•é‡è¯•çŠ¶æ€
			lifecycleManager.HandleError(err)
			lifecycleManager.UpdateStatus("retry", i+1, attempt-1)
			
			slog.Warn(fmt.Sprintf("ğŸ”„ [æµå¼é‡è¯•] [%s] ç«¯ç‚¹: %s, å°è¯•: %d/%d, é”™è¯¯: %v", 
				connID, ep.Config.Name, attempt, h.config.Retry.MaxAttempts, err))
			
			// å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…é‡è¯•å»¶è¿Ÿ
			if attempt < h.config.Retry.MaxAttempts {
				// è®¡ç®—é‡è¯•å»¶è¿Ÿ
				delay := h.calculateRetryDelay(attempt)
				slog.Info(fmt.Sprintf("â³ [ç­‰å¾…é‡è¯•] [%s] ç«¯ç‚¹: %s, å»¶è¿Ÿ: %v", 
					connID, ep.Config.Name, delay))
				
				// å‘å®¢æˆ·ç«¯å‘é€é‡è¯•ä¿¡æ¯
				fmt.Fprintf(w, "data: retry: é‡è¯•ç«¯ç‚¹ %s (å°è¯• %d/%d)ï¼Œç­‰å¾… %v...\n\n", 
					ep.Config.Name, attempt+1, h.config.Retry.MaxAttempts, delay)
				flusher.Flush()
				
				// ç­‰å¾…å»¶è¿Ÿï¼ŒåŒæ—¶æ£€æŸ¥å–æ¶ˆ
				select {
				case <-ctx.Done():
					slog.Info(fmt.Sprintf("ğŸš« [é‡è¯•å–æ¶ˆ] [%s] ç­‰å¾…é‡è¯•æœŸé—´æ£€æµ‹åˆ°å–æ¶ˆ", connID))
					lifecycleManager.UpdateStatus("cancelled", i+1, attempt)
					fmt.Fprintf(w, "data: cancelled: å®¢æˆ·ç«¯å–æ¶ˆè¯·æ±‚\n\n")
					flusher.Flush()
					return
				case <-time.After(delay):
					// ç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
				}
			}
		}
		
		// ğŸ”§ å½“å‰ç«¯ç‚¹æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
		if !endpointSuccess {
			slog.Warn(fmt.Sprintf("âŒ [ç«¯ç‚¹å¤±è´¥] [%s] ç«¯ç‚¹: %s æ‰€æœ‰ %d æ¬¡é‡è¯•å‡å¤±è´¥", 
				connID, ep.Config.Name, h.config.Retry.MaxAttempts))
			
			// å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªç«¯ç‚¹ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
			if i < len(endpoints)-1 {
				fmt.Fprintf(w, "data: retry: åˆ‡æ¢åˆ°å¤‡ç”¨ç«¯ç‚¹: %s\n\n", endpoints[i+1].Config.Name)
				flusher.Flush()
				continue
			}
		}
	}
	
	// ğŸ”§ æ‰€æœ‰å½“å‰ç«¯ç‚¹éƒ½å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥æŒ‚èµ·è¯·æ±‚
	// æ³¨æ„ï¼šå®¢æˆ·ç«¯å–æ¶ˆé”™è¯¯å·²åœ¨ä¸Šé¢ç»Ÿä¸€å¤„ç†ï¼Œè¿™é‡Œä¸ä¼šæ‰§è¡Œåˆ°
	
	// åˆ›å»ºä¸´æ—¶çš„RetryHandleræ¥è®¿é—®æŒ‚èµ·é€»è¾‘
	tempRetryHandler := NewRetryHandler(h.config)
	tempRetryHandler.SetEndpointManager(h.endpointManager)
	tempRetryHandler.SetUsageTracker(h.usageTracker)
	
	// æ£€æŸ¥æ˜¯å¦åº”è¯¥æŒ‚èµ·è¯·æ±‚
	if tempRetryHandler.shouldSuspendRequest(ctx) {
		fmt.Fprintf(w, "data: suspend: å½“å‰æ‰€æœ‰ç»„å‡ä¸å¯ç”¨ï¼Œè¯·æ±‚å·²æŒ‚èµ·ç­‰å¾…ç»„åˆ‡æ¢...\n\n")
		flusher.Flush()
		
		slog.Info(fmt.Sprintf("â¸ï¸ [æµå¼æŒ‚èµ·] [%s] è¯·æ±‚å·²æŒ‚èµ·ç­‰å¾…ç»„åˆ‡æ¢", connID))
		
		// ç­‰å¾…ç»„åˆ‡æ¢
		if tempRetryHandler.waitForGroupSwitch(ctx, connID) {
			slog.Info(fmt.Sprintf("ğŸš€ [æŒ‚èµ·æ¢å¤] [%s] ç»„åˆ‡æ¢å®Œæˆï¼Œé‡æ–°è·å–ç«¯ç‚¹", connID))
			fmt.Fprintf(w, "data: resume: ç»„åˆ‡æ¢å®Œæˆï¼Œæ¢å¤å¤„ç†...\n\n")
			flusher.Flush()
			
			// é‡æ–°è·å–å¥åº·ç«¯ç‚¹
			var newEndpoints []*endpoint.Endpoint
			if h.endpointManager.GetConfig().Strategy.Type == "fastest" && h.endpointManager.GetConfig().Strategy.FastTestEnabled {
				newEndpoints = h.endpointManager.GetFastestEndpointsWithRealTimeTest(ctx)
			} else {
				newEndpoints = h.endpointManager.GetHealthyEndpoints()
			}
			
			if len(newEndpoints) > 0 {
				// æ›´æ–°ç«¯ç‚¹åˆ—è¡¨ï¼Œé‡æ–°å¼€å§‹å¤„ç†
				endpoints = newEndpoints
				slog.Info(fmt.Sprintf("ğŸ”„ [é‡æ–°å¼€å§‹] [%s] è·å–åˆ° %d ä¸ªæ–°ç«¯ç‚¹ï¼Œé‡æ–°å¼€å§‹æµå¼å¤„ç†", connID, len(newEndpoints)))
				
				// ğŸ”§ [ç”Ÿå‘½å‘¨æœŸä¿®å¤] æ¢å¤æ—¶å¿…é¡»æ›´æ–°ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨çš„ç«¯ç‚¹ä¿¡æ¯
				// è®¾ç½®ç¬¬ä¸€ä¸ªæ–°ç«¯ç‚¹çš„ä¿¡æ¯åˆ°ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
				firstEndpoint := newEndpoints[0]
				lifecycleManager.SetEndpoint(firstEndpoint.Config.Name, firstEndpoint.Config.Group)
				
				// é‡æ–°è·å–å¥åº·ç«¯ç‚¹å¹¶é‡æ–°å°è¯•ï¼ˆé€’å½’è°ƒç”¨ï¼‰
				h.executeStreamingWithRetry(ctx, w, r, bodyBytes, lifecycleManager, flusher)
				return
			}
		}
	}
	
	slog.Warn(fmt.Sprintf("âš ï¸ [æŒ‚èµ·å¤±è´¥] [%s] æŒ‚èµ·ç­‰å¾…è¶…æ—¶æˆ–å¤±è´¥", connID))
	
	// æœ€ç»ˆå¤±è´¥å¤„ç† - ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å·²å¤„ç†é”™è¯¯åˆ†ç±»
	lifecycleManager.UpdateStatus("error", len(endpoints), http.StatusBadGateway)
	fmt.Fprintf(w, "data: error: All endpoints failed, last error: %v\n\n", lastErr)
	flusher.Flush()
	return
}

// handleRegularRequestUnified ç»Ÿä¸€å¸¸è§„è¯·æ±‚å¤„ç†
// æ•´åˆé”™è¯¯æ¢å¤æœºåˆ¶å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†çš„å¸¸è§„è¯·æ±‚å¤„ç†
func (h *Handler) handleRegularRequestUnified(ctx context.Context, w http.ResponseWriter, r *http.Request, bodyBytes []byte, lifecycleManager *RequestLifecycleManager) {
	connID := lifecycleManager.GetRequestID()
	var selectedEndpointName string
	
	slog.Info(fmt.Sprintf("ğŸ”„ [å¸¸è§„æ¶æ„] [%s] ä½¿ç”¨unified v2æ¶æ„", connID))
	
	// åˆ›å»ºé”™è¯¯æ¢å¤ç®¡ç†å™¨
	errorRecovery := NewErrorRecoveryManager(h.usageTracker)
	
	// ä½¿ç”¨é‡è¯•å¤„ç†å™¨æ‰§è¡Œè¯·æ±‚
	operation := func(ep *endpoint.Endpoint, connectionID string) (*http.Response, error) {
		// æ›´æ–°ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ä¿¡æ¯
		selectedEndpointName = ep.Config.Name
		lifecycleManager.SetEndpoint(ep.Config.Name, ep.Config.Group)
		lifecycleManager.UpdateStatus("forwarding", 0, 0)
		
		// æ›´æ–°ç›‘æ§ä¸­é—´ä»¶çš„è¿æ¥ç«¯ç‚¹ä¿¡æ¯
		if mm, ok := h.retryHandler.monitoringMiddleware.(interface{
			UpdateConnectionEndpoint(connID, endpoint string)
		}); ok && connectionID != "" {
			mm.UpdateConnectionEndpoint(connectionID, ep.Config.Name)
		}
		
		// åˆ›å»ºç›®æ ‡è¯·æ±‚
		targetURL := ep.Config.URL + r.URL.Path
		if r.URL.RawQuery != "" {
			targetURL += "?" + r.URL.RawQuery
		}

		req, err := http.NewRequestWithContext(ctx, r.Method, targetURL, bytes.NewReader(bodyBytes))
		if err != nil {
			return nil, fmt.Errorf("failed to create request: %w", err)
		}

		// å¤åˆ¶å’Œä¿®æ”¹å¤´éƒ¨
		h.copyHeaders(r, req, ep)

		// åˆ›å»ºHTTPä¼ è¾“
		httpTransport, err := transport.CreateTransport(h.config)
		if err != nil {
			return nil, fmt.Errorf("failed to create transport: %w", err)
		}
		
		client := &http.Client{
			Timeout:   ep.Config.Timeout,
			Transport: httpTransport,
		}

		// æ‰§è¡Œè¯·æ±‚
		resp, err := client.Do(req)
		if err != nil {
			// åˆ†ç±»é”™è¯¯å¹¶è®°å½•
			errorCtx := errorRecovery.ClassifyError(err, connID, ep.Config.Name, ep.Config.Group, 0)
			lifecycleManager.HandleError(err)
			
			slog.Warn("ğŸ”„ Regular request failed", "request_id", connID, "endpoint", ep.Config.Name, 
				"error_type", errorRecovery.getErrorTypeName(errorCtx.ErrorType), "error", err)
			
			return nil, fmt.Errorf("request failed: %w", err)
		}

		return resp, nil
	}

	// æ‰§è¡Œè¯·æ±‚ä¸é‡è¯•é€»è¾‘
	finalResp, lastErr := h.retryHandler.ExecuteWithContext(ctx, operation, connID)
	
	// åœ¨ä¸Šä¸‹æ–‡ä¸­å­˜å‚¨é€‰ä¸­çš„ç«¯ç‚¹ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•
	if selectedEndpointName != "" {
		*r = *r.WithContext(context.WithValue(r.Context(), "selected_endpoint", selectedEndpointName))
	}
	
	// å¤„ç†é”™è¯¯æƒ…å†µ
	if lastErr != nil {
		errorCtx := errorRecovery.ClassifyError(lastErr, connID, selectedEndpointName, "", 0)
		lifecycleManager.HandleError(lastErr)
		errorRecovery.HandleFinalFailure(errorCtx)
		
		// æ ¹æ®é”™è¯¯ç±»å‹è¿”å›é€‚å½“çš„çŠ¶æ€ç 
		if strings.Contains(lastErr.Error(), "no healthy endpoints") {
			http.Error(w, "Service Unavailable: No healthy endpoints available", http.StatusServiceUnavailable)
		} else {
			http.Error(w, "All endpoints failed: "+lastErr.Error(), http.StatusBadGateway)
		}
		return
	}

	if finalResp == nil {
		err := fmt.Errorf("no response received from any endpoint")
		lifecycleManager.HandleError(err)
		http.Error(w, err.Error(), http.StatusBadGateway)
		return
	}

	defer finalResp.Body.Close()

	// æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
	lifecycleManager.UpdateStatus("processing", 0, finalResp.StatusCode)

	// å¤åˆ¶å“åº”å¤´ï¼ˆæ’é™¤Content-Encodingç”¨äºgzipå¤„ç†ï¼‰
	h.copyResponseHeaders(finalResp, w)

	// å†™å…¥çŠ¶æ€ç 
	w.WriteHeader(finalResp.StatusCode)

	// è¯»å–å¹¶å¤„ç†å“åº”ä½“
	responseBytes, err := h.processResponseBody(finalResp)
	if err != nil {
		lifecycleManager.HandleError(fmt.Errorf("failed to process response: %w", err))
		slog.Error("Failed to process response body", "request_id", connID, "error", err)
		return
	}

	// å†™å…¥å“åº”ä½“åˆ°å®¢æˆ·ç«¯
	if _, err := w.Write(responseBytes); err != nil {
		lifecycleManager.HandleError(fmt.Errorf("failed to write response: %w", err))
		slog.Error("Failed to write response to client", "request_id", connID, "error", err)
		return
	}

	// å¯¹äºå¸¸è§„è¯·æ±‚ï¼Œå°è¯•è§£æTokenä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
	h.analyzeResponseForTokensUnified(responseBytes, connID, selectedEndpointName, lifecycleManager)

	// å®Œæˆè¯·æ±‚
	lifecycleManager.UpdateStatus("completed", 0, finalResp.StatusCode)
	
	slog.Info(fmt.Sprintf("âœ… [å¸¸è§„è¯·æ±‚å®Œæˆ] [%s] ç«¯ç‚¹: %s, çŠ¶æ€ç : %d, å“åº”å¤§å°: %då­—èŠ‚", 
		connID, selectedEndpointName, finalResp.StatusCode, len(responseBytes)))
}

// handleRegularRequest handles non-streaming requests
func (h *Handler) handleRegularRequest(ctx context.Context, w http.ResponseWriter, r *http.Request, bodyBytes []byte) {
	var selectedEndpointName string
	
	// Get connection ID from request context (set by logging middleware)
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	operation := func(ep *endpoint.Endpoint, connectionID string) (*http.Response, error) {
		// Store the selected endpoint name for logging
		selectedEndpointName = ep.Config.Name
		
		// Update connection endpoint in monitoring (if we have a monitoring middleware)
		if mm, ok := h.retryHandler.monitoringMiddleware.(interface{
			UpdateConnectionEndpoint(connID, endpoint string)
		}); ok && connectionID != "" {
			mm.UpdateConnectionEndpoint(connectionID, ep.Config.Name)
		}
		
		// Create request to target endpoint
		targetURL := ep.Config.URL + r.URL.Path
		if r.URL.RawQuery != "" {
			targetURL += "?" + r.URL.RawQuery
		}

		req, err := http.NewRequestWithContext(ctx, r.Method, targetURL, bytes.NewReader(bodyBytes))
		if err != nil {
			return nil, fmt.Errorf("failed to create request: %w", err)
		}

		// Copy headers from original request
		h.copyHeaders(r, req, ep)

		// Create HTTP client with timeout and proxy support
		httpTransport, err := transport.CreateTransport(h.config)
		if err != nil {
			return nil, fmt.Errorf("failed to create transport: %w", err)
		}
		
		client := &http.Client{
			Timeout:   ep.Config.Timeout,
			Transport: httpTransport,
		}

		// Make the request
		resp, err := client.Do(req)
		if err != nil {
			return nil, fmt.Errorf("request failed: %w", err)
		}

		// Return the response - retry logic will check status code
		return resp, nil
	}

	// Execute with retry logic
	finalResp, lastErr := h.retryHandler.ExecuteWithContext(ctx, operation, connID)
	
	// Store selected endpoint info in request context for logging
	if selectedEndpointName != "" {
		*r = *r.WithContext(context.WithValue(r.Context(), "selected_endpoint", selectedEndpointName))
	}
	
	if lastErr != nil {
		// Check if the error is due to no healthy endpoints
		if strings.Contains(lastErr.Error(), "no healthy endpoints") {
			http.Error(w, "Service Unavailable: No healthy endpoints available", http.StatusServiceUnavailable)
		} else {
			// If all retries failed, return error
			http.Error(w, "All endpoints failed: "+lastErr.Error(), http.StatusBadGateway)
		}
		return
	}

	if finalResp == nil {
		http.Error(w, "No response received from any endpoint", http.StatusBadGateway)
		return
	}

	defer finalResp.Body.Close()

	// Copy response headers (except Content-Encoding for gzip handling)
	for key, values := range finalResp.Header {
		// Skip Content-Encoding header as we handle gzip decompression ourselves
		if strings.ToLower(key) == "content-encoding" {
			continue
		}
		for _, value := range values {
			w.Header().Add(key, value)
		}
	}

	// Set status code
	w.WriteHeader(finalResp.StatusCode)

	// Read and decompress response body if needed
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ”„ [å¼€å§‹è¯»å–å“åº”] [%s] ç«¯ç‚¹: %s, Content-Encoding: %s", 
		connID, selectedEndpointName, finalResp.Header.Get("Content-Encoding")))
	
	bodyBytes, err := h.readAndDecompressResponse(ctx, finalResp, selectedEndpointName)
	if err != nil {
		slog.ErrorContext(ctx, fmt.Sprintf("âŒ [å“åº”è¯»å–å¤±è´¥] [%s] ç«¯ç‚¹: %s, é”™è¯¯: %v", connID, selectedEndpointName, err))
		http.Error(w, "Failed to read response: "+err.Error(), http.StatusInternalServerError)
		return
	}

	slog.DebugContext(ctx, fmt.Sprintf("âœ… [å“åº”è¯»å–æˆåŠŸ] [%s] ç«¯ç‚¹: %s, é•¿åº¦: %då­—èŠ‚", 
		connID, selectedEndpointName, len(bodyBytes)))

	bodyContent := string(bodyBytes)
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ› [è°ƒè¯•å“åº”å¤´] ç«¯ç‚¹: %s, å“åº”å¤´: %v", selectedEndpointName, finalResp.Header))
	
	// Pass the complete response content to logger - let the logger decide how to handle truncation
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ› [è°ƒè¯•å“åº”] ç«¯ç‚¹: %s, çŠ¶æ€ç : %d, é•¿åº¦: %då­—èŠ‚, å“åº”å†…å®¹: %s", 
		selectedEndpointName, finalResp.StatusCode, len(bodyContent), bodyContent))
	
	// Analyze the complete response for token usage
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ” [å¼€å§‹Tokenåˆ†æ] [%s] ç«¯ç‚¹: %s", connID, selectedEndpointName))
	h.analyzeResponseForTokens(ctx, bodyContent, selectedEndpointName, r)
	slog.DebugContext(ctx, fmt.Sprintf("âœ… [Tokenåˆ†æå®Œæˆ] [%s] ç«¯ç‚¹: %s", connID, selectedEndpointName))
	
	// Write the body to client
	_, writeErr := w.Write(bodyBytes)
	if writeErr != nil {
	}
}

// readAndDecompressResponse reads and decompresses the response body based on Content-Encoding
func (h *Handler) readAndDecompressResponse(ctx context.Context, resp *http.Response, endpointName string) ([]byte, error) {
	// Read the raw response body
	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response body: %w", err)
	}

	// Check Content-Encoding header
	contentEncoding := strings.ToLower(strings.TrimSpace(resp.Header.Get("Content-Encoding")))
	if contentEncoding == "" {
		// No encoding, return as is
		return bodyBytes, nil
	}

	// Handle different compression methods
	switch contentEncoding {
	case "gzip":
		return h.decompressGzip(ctx, bodyBytes, endpointName)
	case "deflate":
		return h.decompressDeflate(ctx, bodyBytes, endpointName)
	case "br":
		return h.decompressBrotli(ctx, bodyBytes, endpointName)
	case "compress":
		return h.decompressLZW(ctx, bodyBytes, endpointName)
	case "identity":
		// Identity means no encoding
		return bodyBytes, nil
	default:
		// Unknown encoding, log warning and return as is
		slog.WarnContext(ctx, fmt.Sprintf("âš ï¸ [å‹ç¼©] æœªçŸ¥çš„ç¼–ç æ–¹å¼ï¼Œç«¯ç‚¹: %s, ç¼–ç : %s", endpointName, contentEncoding))
		return bodyBytes, nil
	}
}

// decompressGzip decompresses gzip encoded content
func (h *Handler) decompressGzip(ctx context.Context, bodyBytes []byte, endpointName string) ([]byte, error) {
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [GZIP] æ£€æµ‹åˆ°gzipç¼–ç å“åº”ï¼Œç«¯ç‚¹: %s, å‹ç¼©é•¿åº¦: %då­—èŠ‚", endpointName, len(bodyBytes)))
	
	gzipReader, err := gzip.NewReader(bytes.NewReader(bodyBytes))
	if err != nil {
		return nil, fmt.Errorf("failed to create gzip reader: %w", err)
	}
	defer gzipReader.Close()

	decompressedBytes, err := io.ReadAll(gzipReader)
	if err != nil {
		return nil, fmt.Errorf("failed to decompress gzip content: %w", err)
	}

	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [GZIP] è§£å‹å®Œæˆï¼Œç«¯ç‚¹: %s, è§£å‹åé•¿åº¦: %då­—èŠ‚", endpointName, len(decompressedBytes)))
	return decompressedBytes, nil
}

// decompressDeflate decompresses deflate encoded content
func (h *Handler) decompressDeflate(ctx context.Context, bodyBytes []byte, endpointName string) ([]byte, error) {
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [DEFLATE] æ£€æµ‹åˆ°deflateç¼–ç å“åº”ï¼Œç«¯ç‚¹: %s, å‹ç¼©é•¿åº¦: %då­—èŠ‚", endpointName, len(bodyBytes)))
	
	deflateReader := flate.NewReader(bytes.NewReader(bodyBytes))
	defer deflateReader.Close()

	decompressedBytes, err := io.ReadAll(deflateReader)
	if err != nil {
		return nil, fmt.Errorf("failed to decompress deflate content: %w", err)
	}

	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [DEFLATE] è§£å‹å®Œæˆï¼Œç«¯ç‚¹: %s, è§£å‹åé•¿åº¦: %då­—èŠ‚", endpointName, len(decompressedBytes)))
	return decompressedBytes, nil
}

// decompressBrotli decompresses Brotli encoded content
func (h *Handler) decompressBrotli(ctx context.Context, bodyBytes []byte, endpointName string) ([]byte, error) {
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [BROTLI] æ£€æµ‹åˆ°brç¼–ç å“åº”ï¼Œç«¯ç‚¹: %s, å‹ç¼©é•¿åº¦: %då­—èŠ‚", endpointName, len(bodyBytes)))
	
	brotliReader := brotli.NewReader(bytes.NewReader(bodyBytes))

	decompressedBytes, err := io.ReadAll(brotliReader)
	if err != nil {
		return nil, fmt.Errorf("failed to decompress brotli content: %w", err)
	}

	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [BROTLI] è§£å‹å®Œæˆï¼Œç«¯ç‚¹: %s, è§£å‹åé•¿åº¦: %då­—èŠ‚", endpointName, len(decompressedBytes)))
	return decompressedBytes, nil
}

// decompressLZW decompresses LZW (compress) encoded content
func (h *Handler) decompressLZW(ctx context.Context, bodyBytes []byte, endpointName string) ([]byte, error) {
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [LZW] æ£€æµ‹åˆ°compressç¼–ç å“åº”ï¼Œç«¯ç‚¹: %s, å‹ç¼©é•¿åº¦: %då­—èŠ‚", endpointName, len(bodyBytes)))
	
	// LZW reader with MSB order (standard for HTTP compress)
	lzwReader := lzw.NewReader(bytes.NewReader(bodyBytes), lzw.MSB, 8)
	defer lzwReader.Close()

	decompressedBytes, err := io.ReadAll(lzwReader)
	if err != nil {
		return nil, fmt.Errorf("failed to decompress LZW content: %w", err)
	}

	slog.DebugContext(ctx, fmt.Sprintf("ğŸ—œï¸ [LZW] è§£å‹å®Œæˆï¼Œç«¯ç‚¹: %s, è§£å‹åé•¿åº¦: %då­—èŠ‚", endpointName, len(decompressedBytes)))
	return decompressedBytes, nil
}

// analyzeResponseForTokens analyzes the complete response body for token usage information
func (h *Handler) analyzeResponseForTokens(ctx context.Context, responseBody, endpointName string, r *http.Request) {
	
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		h.parseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event:message_delta") || 
	   strings.Contains(responseBody, "event: message_delta") {
		h.parseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Method 2: Try to parse as single JSON response
	if strings.HasPrefix(strings.TrimSpace(responseBody), "{") && strings.Contains(responseBody, "usage") {
		h.parseJSONTokens(ctx, responseBody, endpointName, connID)
		return
	}

	// Fallback: No token information found, mark request as completed with non_token_response model
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ¯ [æ— Tokenå“åº”] ç«¯ç‚¹: %s, è¿æ¥: %s - å“åº”ä¸åŒ…å«tokenä¿¡æ¯ï¼Œæ ‡è®°ä¸ºå®Œæˆ", endpointName, connID))
	
	// Update request status to completed and set model name to "non_token_response"
	if h.usageTracker != nil && connID != "" {
		// Create empty token usage for consistent completion tracking
		emptyTokens := &tracking.TokenUsage{
			InputTokens:         0,
			OutputTokens:        0,
			CacheCreationTokens: 0,
			CacheReadTokens:     0,
		}
		
		// Record completion with non_token_response model name and zero duration (since we don't track start time here)
		h.usageTracker.RecordRequestComplete(connID, "non_token_response", emptyTokens, 0)
		
		slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å·²æ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response", connID))
	}
}

// parseSSETokens parses SSE format response for token usage or error events
func (h *Handler) parseSSETokens(ctx context.Context, responseBody, endpointName, connID string) {
	tokenParser := NewTokenParserWithUsageTracker(connID, h.usageTracker)
	lines := strings.Split(responseBody, "\n")
	
	foundTokenUsage := false
	hasErrorEvent := false
	
	// Check if response contains error events first
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		hasErrorEvent = true
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] ç«¯ç‚¹: %s, è¿æ¥: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", endpointName, connID))
	}
	
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			foundTokenUsage = true
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] ç«¯ç‚¹: %s, è¿æ¥: %s - æˆåŠŸè§£ætokenä¿¡æ¯", endpointName, connID))
			
			// Record token usage in monitoring middleware if available
			if mm, ok := h.retryHandler.monitoringMiddleware.(interface{
				RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
			}); ok && connID != "" {
				mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			}
			
			// Token usage has already been recorded in usage tracker by TokenParser
			// So we can return successfully here
			return
		}
	}
	
	// If we found an error event, the parseErrorEvent method would have already handled it
	if hasErrorEvent {
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] ç«¯ç‚¹: %s, è¿æ¥: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", endpointName, connID))
		return
	}
	
	if !foundTokenUsage {
		slog.InfoContext(ctx, fmt.Sprintf("ğŸš« [SSEè§£æ] ç«¯ç‚¹: %s, è¿æ¥: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", endpointName, connID))
	}
}

// parseJSONTokens parses single JSON response for token usage
func (h *Handler) parseJSONTokens(ctx context.Context, responseBody, endpointName, connID string) {
	// Simulate SSE parsing for a single JSON response
	tokenParser := NewTokenParserWithUsageTracker(connID, h.usageTracker)
	
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// ğŸ†• First extract model information directly from JSON
	var jsonResp map[string]interface{}
	if err := json.Unmarshal([]byte(responseBody), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			tokenParser.SetModelName(model)
			slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage
		if mm, ok := h.retryHandler.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
	}
}

// copyHeaders copies headers from source to destination request
func (h *Handler) copyHeaders(src *http.Request, dst *http.Request, ep *endpoint.Endpoint) {
	// List of headers to skip/remove
	skipHeaders := map[string]bool{
		"host":          true, // We'll set this based on target endpoint
		"authorization": true, // We'll add our own if configured
		"x-api-key":     true, // Remove sensitive client API keys
	}
	
	// Copy all headers except those we want to skip
	for key, values := range src.Header {
		if skipHeaders[strings.ToLower(key)] {
			continue
		}
		
		for _, value := range values {
			dst.Header.Add(key, value)
		}
	}

	// Set Host header based on target endpoint URL
	if u, err := url.Parse(ep.Config.URL); err == nil {
		dst.Header.Set("Host", u.Host)
		// Also set the Host field directly on the request for proper HTTP/1.1 behavior
		dst.Host = u.Host
	}

	// Add or override Authorization header with dynamically resolved token
	token := h.endpointManager.GetTokenForEndpoint(ep)
	if token != "" {
		dst.Header.Set("Authorization", "Bearer "+token)
	}

	// Add or override X-Api-Key header with dynamically resolved api-key
	apiKey := h.endpointManager.GetApiKeyForEndpoint(ep)
	if apiKey != "" {
		dst.Header.Set("X-Api-Key", apiKey)
	}

	// Add custom headers from endpoint configuration
	for key, value := range ep.Config.Headers {
		dst.Header.Set(key, value)
	}

	// Remove hop-by-hop headers
	hopByHopHeaders := []string{
		"Connection",
		"Keep-Alive", 
		"Proxy-Authenticate",
		"Proxy-Authorization",
		"Te",
		"Trailers",
		"Transfer-Encoding",
		"Upgrade",
	}

	for _, header := range hopByHopHeaders {
		dst.Header.Del(header)
	}
}

// UpdateConfig updates the handler configuration
func (h *Handler) UpdateConfig(cfg *config.Config) {
	h.config = cfg
	
	// Update retry handler with new config
	h.retryHandler.UpdateConfig(cfg)
}

// forwardRequestToEndpoint è½¬å‘è¯·æ±‚åˆ°æŒ‡å®šç«¯ç‚¹
func (h *Handler) forwardRequestToEndpoint(ctx context.Context, r *http.Request, bodyBytes []byte, ep *endpoint.Endpoint) (*http.Response, error) {
	// åˆ›å»ºç›®æ ‡URL
	targetURL := ep.Config.URL + r.URL.Path
	if r.URL.RawQuery != "" {
		targetURL += "?" + r.URL.RawQuery
	}

	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequestWithContext(ctx, r.Method, targetURL, bytes.NewReader(bodyBytes))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	// å¤åˆ¶å’Œä¿®æ”¹å¤´éƒ¨
	h.copyHeaders(r, req, ep)

	// åˆ›å»ºHTTPä¼ è¾“
	httpTransport, err := transport.CreateTransport(h.config)
	if err != nil {
		return nil, fmt.Errorf("failed to create transport: %w", err)
	}
	
	// ä¼˜åŒ–ä¼ è¾“è®¾ç½®ç”¨äºæµå¼å¤„ç†
	httpTransport.DisableKeepAlives = false
	httpTransport.MaxIdleConns = 10
	httpTransport.MaxIdleConnsPerHost = 2
	httpTransport.IdleConnTimeout = 0 // æ— ç©ºé—²è¶…æ—¶
	httpTransport.TLSHandshakeTimeout = 10 * time.Second
	httpTransport.ExpectContinueTimeout = 1 * time.Second
	httpTransport.ResponseHeaderTimeout = 15 * time.Second
	httpTransport.DisableCompression = true // ç¦ç”¨å‹ç¼©ä»¥é˜²ç¼“å†²å»¶è¿Ÿ
	httpTransport.WriteBufferSize = 4096    // è¾ƒå°çš„å†™ç¼“å†²åŒº
	httpTransport.ReadBufferSize = 4096     // è¾ƒå°çš„è¯»ç¼“å†²åŒº
	
	client := &http.Client{
		Timeout:   0, // æµå¼è¯·æ±‚æ— è¶…æ—¶
		Transport: httpTransport,
	}

	// æ‰§è¡Œè¯·æ±‚
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("request failed: %w", err)
	}

	// æ£€æŸ¥å“åº”çŠ¶æ€
	if resp.StatusCode >= 400 {
		resp.Body.Close()
		return nil, fmt.Errorf("endpoint returned error: %d", resp.StatusCode)
	}

	return resp, nil
}

// copyResponseHeaders å¤åˆ¶å“åº”å¤´åˆ°å®¢æˆ·ç«¯
func (h *Handler) copyResponseHeaders(resp *http.Response, w http.ResponseWriter) {
	for key, values := range resp.Header {
		// è·³è¿‡ä¸€äº›ä¸åº”è¯¥å¤åˆ¶çš„å¤´éƒ¨
		switch key {
		case "Content-Length", "Transfer-Encoding", "Connection", "Content-Encoding":
			continue
		}
		for _, value := range values {
			w.Header().Add(key, value)
		}
	}
}

// processResponseBody å¤„ç†å“åº”ä½“ï¼ˆåŒ…æ‹¬è§£å‹ç¼©ï¼‰
func (h *Handler) processResponseBody(resp *http.Response) ([]byte, error) {
	var reader io.Reader = resp.Body
	
	// æ£€æŸ¥å†…å®¹ç¼–ç å¹¶è§£å‹ç¼©
	encoding := resp.Header.Get("Content-Encoding")
	switch encoding {
	case "gzip":
		gzReader, err := gzip.NewReader(resp.Body)
		if err != nil {
			return nil, fmt.Errorf("failed to create gzip reader: %w", err)
		}
		defer gzReader.Close()
		reader = gzReader
		
	case "deflate":
		reader = flate.NewReader(resp.Body)
		
	case "br":
		reader = brotli.NewReader(resp.Body)
		
	case "compress":
		reader = lzw.NewReader(resp.Body, lzw.LSB, 8)
	}
	
	// è¯»å–å“åº”ä½“
	responseBytes, err := io.ReadAll(reader)
	if err != nil {
		return nil, fmt.Errorf("failed to read response body: %w", err)
	}
	
	return responseBytes, nil
}

// analyzeResponseForTokensWithLifecycle analyzes response with accurate duration from lifecycle manager
func (h *Handler) analyzeResponseForTokensWithLifecycle(ctx context.Context, responseBody, endpointName string, r *http.Request, lifecycleManager *RequestLifecycleManager) {
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		h.parseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event:message_delta") ||
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event: message_delta") {
		h.parseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Method 2: Direct JSON analysis for non-SSE responses
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// Try to parse as JSON and extract model information
	var jsonData map[string]interface{}
	var model string
	
	if err := json.Unmarshal([]byte(responseBody), &jsonData); err == nil {
		// Extract model information if available
		if modelValue, exists := jsonData["model"]; exists {
			if modelStr, ok := modelValue.(string); ok {
				model = modelStr
				slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
			}
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser := NewTokenParser()
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage to monitoring middleware
		if mm, ok := h.retryHandler.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
		
		// ğŸ”§ ä¿®å¤ï¼šåŒæ—¶ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä½¿ç”¨å‡†ç¡®çš„å¤„ç†æ—¶é—´
		if h.usageTracker != nil && connID != "" && lifecycleManager != nil {
			// è½¬æ¢Tokenæ ¼å¼
			dbTokens := &tracking.TokenUsage{
				InputTokens:         tokenUsage.InputTokens,
				OutputTokens:        tokenUsage.OutputTokens,
				CacheCreationTokens: tokenUsage.CacheCreationTokens,
				CacheReadTokens:     tokenUsage.CacheReadTokens,
			}
			
			// ä½¿ç”¨æå–çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨default
			modelName := "default"
			if model != "" {
				modelName = model
			}
			
			// ğŸ¯ ä½¿ç”¨lifecycleManagerè·å–å‡†ç¡®çš„å¤„ç†æ—¶é—´
			duration := lifecycleManager.GetDuration()
			
			// ä¿å­˜åˆ°æ•°æ®åº“
			h.usageTracker.RecordRequestComplete(connID, modelName, dbTokens, duration)
			slog.InfoContext(ctx, "ğŸ’¾ [æ•°æ®åº“ä¿å­˜] JSONè§£æçš„Tokenä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“",
				"request_id", connID, "model", modelName, 
				"inputTokens", dbTokens.InputTokens, "outputTokens", dbTokens.OutputTokens,
				"duration", duration)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
		
		// Fallback: No token information found, mark request as completed with default model
		if h.usageTracker != nil && connID != "" && lifecycleManager != nil {
			emptyTokens := &tracking.TokenUsage{
				InputTokens: 0, OutputTokens: 0, 
				CacheCreationTokens: 0, CacheReadTokens: 0,
			}
			duration := lifecycleManager.GetDuration()
			h.usageTracker.RecordRequestComplete(connID, "non_token_response", emptyTokens, duration)
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å·²æ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response, å¤„ç†æ—¶é—´: %v", 
				connID, duration))
		}
	}
}

// analyzeResponseForTokensUnified ç®€åŒ–ç‰ˆæœ¬çš„Tokenåˆ†æï¼ˆç”¨äºç»Ÿä¸€æ¥å£ï¼‰
func (h *Handler) analyzeResponseForTokensUnified(responseBytes []byte, connID, endpointName string, lifecycleManager *RequestLifecycleManager) {
	if len(responseBytes) == 0 {
		return
	}
	
	responseStr := string(responseBytes)
	
	// ä½¿ç”¨ç°æœ‰çš„Tokenåˆ†ææ–¹æ³•ï¼ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„Requestå¯¹è±¡ï¼‰
	req := &http.Request{} // åˆ›å»ºä¸€ä¸ªç©ºçš„requestå¯¹è±¡
	req = req.WithContext(context.WithValue(context.Background(), "conn_id", connID))
	
	// è°ƒç”¨ç°æœ‰çš„åˆ†ææ–¹æ³•ï¼Œä¼ å…¥lifecycleManagerä»¥è·å–å‡†ç¡®çš„duration
	h.analyzeResponseForTokensWithLifecycle(req.Context(), responseStr, endpointName, req, lifecycleManager)
}

// calculateRetryDelay è®¡ç®—é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ç®—æ³•ï¼‰
func (h *Handler) calculateRetryDelay(attempt int) time.Duration {
	// ä½¿ç”¨ä¸RetryHandlerç›¸åŒçš„è®¡ç®—é€»è¾‘
	multiplier := math.Pow(h.config.Retry.Multiplier, float64(attempt-1))
	delay := time.Duration(float64(h.config.Retry.BaseDelay) * multiplier)
	
	// é™åˆ¶åœ¨æœ€å¤§å»¶è¿ŸèŒƒå›´å†…
	if delay > h.config.Retry.MaxDelay {
		delay = h.config.Retry.MaxDelay
	}
	
	return delay
}