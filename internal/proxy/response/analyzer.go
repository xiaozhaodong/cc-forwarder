package response

import (
	"context"
	"encoding/json"
	"fmt"
	"log/slog"
	"net/http"
	"strings"
	"time"

	"cc-forwarder/internal/monitor"
	"cc-forwarder/internal/tracking"
	"cc-forwarder/internal/utils"
)

// ResponseFormat å®šä¹‰å“åº”æ ¼å¼ç±»å‹
type ResponseFormat int

const (
	FormatUnknown ResponseFormat = iota
	FormatJSON
	FormatSSE
	FormatPlainText
)

// RequestLifecycleManager å®šä¹‰ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¥å£
type RequestLifecycleManager interface {
	GetDuration() time.Duration
}

// TokenParser å®šä¹‰token parseræ¥å£
type TokenParser interface {
	ParseSSELine(line string) *monitor.TokenUsage
	SetModelName(model string)
}

// TokenParserProvider æä¾›token parseråˆ›å»ºåŠŸèƒ½
type TokenParserProvider interface {
	NewTokenParser() TokenParser
	NewTokenParserWithUsageTracker(requestID string, usageTracker *tracking.UsageTracker) TokenParser
}

// TokenAnalyzer è´Ÿè´£åˆ†æå“åº”ä¸­çš„Tokenä½¿ç”¨ä¿¡æ¯
type TokenAnalyzer struct {
	usageTracker         *tracking.UsageTracker
	monitoringMiddleware interface{}
	tokenParserProvider  TokenParserProvider
}

// NewTokenAnalyzer åˆ›å»ºæ–°çš„TokenAnalyzerå®ä¾‹
func NewTokenAnalyzer(usageTracker *tracking.UsageTracker, monitoringMiddleware interface{}, provider TokenParserProvider) *TokenAnalyzer {
	return &TokenAnalyzer{
		usageTracker:         usageTracker,
		monitoringMiddleware: monitoringMiddleware,
		tokenParserProvider:  provider,
	}
}

// AnalyzeResponseForTokens analyzes the complete response body for token usage information
// ğŸ†• [ä¿®å¤] ä½¿ç”¨æ–°çš„ä¸‰å±‚é˜²æŠ¤æ ¼å¼æ£€æµ‹ç³»ç»Ÿï¼Œé¿å…JSONå“åº”è¢«è¯¯åˆ¤ä¸ºSSE
func (a *TokenAnalyzer) AnalyzeResponseForTokens(ctx context.Context, responseBody, endpointName string, r *http.Request) {

	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}

	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚",
		connID, endpointName, len(responseBody)))

	// ğŸ†• [ä¿®å¤] ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼æ£€æµ‹æ›¿ä»£strings.Containsåˆ¤æ–­
	format := detectResponseFormat(responseBody)
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [æ ¼å¼æ£€æµ‹] [%s] å“åº”æ ¼å¼: %s, é•¿åº¦: %d",
		connID, formatName(format), len(responseBody)))

	// ğŸ†• [ä¿®å¤] åŸºäºæ£€æµ‹ç»“æœè¿›è¡Œæ™ºèƒ½è·¯ç”±
	switch format {
	case FormatJSON:
		// âœ… æ˜ç¡®æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨JSONè§£æå™¨
		slog.DebugContext(ctx, fmt.Sprintf("ğŸ” [JSONè·¯ç”±] [%s] æ£€æµ‹ä¸ºJSONæ ¼å¼ï¼Œä½¿ç”¨JSONè§£æå™¨", connID))
		a.ParseJSONTokens(ctx, responseBody, endpointName, connID)
		return

	case FormatSSE:
		// âœ… æ˜ç¡®æ˜¯SSEï¼Œä½¿ç”¨SSEè§£æå™¨
		slog.DebugContext(ctx, fmt.Sprintf("ğŸŒŠ [SSEè·¯ç”±] [%s] æ£€æµ‹ä¸ºSSEæ ¼å¼ï¼Œä½¿ç”¨SSEè§£æå™¨", connID))
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return

	default:
		// âš ï¸ æ ¼å¼æœªçŸ¥ï¼Œå¯ç”¨é˜²æŠ¤æ€§å›é€€æœºåˆ¶
		slog.DebugContext(ctx, fmt.Sprintf("â“ [æœªçŸ¥æ ¼å¼] [%s] æ ¼å¼æ£€æµ‹å¤±è´¥ï¼Œå¯ç”¨å›é€€æœºåˆ¶", connID))
		tokenUsage, modelName := a.parseWithFallback(responseBody, connID, endpointName)
		if tokenUsage != nil {
			// å›é€€æœºåˆ¶æˆåŠŸæ‰¾åˆ°Tokenä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [å›é€€æˆåŠŸ] [%s] æ¨¡å‹: %s, Tokenä¿¡æ¯å·²è§£æ", connID, modelName))
			return
		}

		// æœ€ç»ˆå¤±è´¥ï¼šæ— Tokenä¿¡æ¯
		slog.InfoContext(ctx, fmt.Sprintf("ğŸ¯ [æ— Tokenå“åº”] ç«¯ç‚¹: %s, è¿æ¥: %s - å“åº”ä¸åŒ…å«tokenä¿¡æ¯ï¼Œæ ‡è®°ä¸ºå®Œæˆ", endpointName, connID))
		if connID != "" {
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s æ£€æµ‹ä¸ºæ— Tokenå“åº”ï¼Œæ¨¡å‹: non_token_response", connID))
		}
	}
}

// ParseSSETokens parses SSE format response for token usage or error events
func (a *TokenAnalyzer) ParseSSETokens(ctx context.Context, responseBody, endpointName, connID string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	lines := strings.Split(responseBody, "\n")
	
	foundTokenUsage := false
	hasErrorEvent := false
	
	// Check if response contains error events first
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		hasErrorEvent = true
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] [%s] ç«¯ç‚¹: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", connID, endpointName))
	}
	
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			foundTokenUsage = true
			// è·å–æ¨¡å‹åç§°(éœ€è¦ç±»å‹æ–­è¨€è·å–TokenParserçš„æ¨¡å‹ä¿¡æ¯)
			modelName := "unknown"
			if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
				modelName = tp.GetModelName()
			}
			
			// è¯¦ç»†æ˜¾ç¤ºtokenä½¿ç”¨ä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] [%s] ç«¯ç‚¹: %s - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d", 
				connID, endpointName, modelName, 
				tokenUsage.InputTokens, tokenUsage.OutputTokens, 
				tokenUsage.CacheCreationTokens, tokenUsage.CacheReadTokens))
			
			// Record token usage in monitoring middleware if available
			if mm, ok := a.monitoringMiddleware.(interface{
				RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
			}); ok && connID != "" {
				mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			}
			
			// âš ï¸ é‡è¦ï¼šTokenParserç°åœ¨åªè´Ÿè´£è§£æï¼Œä¸ç›´æ¥è®°å½•åˆ°æ•°æ®åº“
			// æ•°æ®åº“è®°å½•ç”±ä¸Šå±‚AnalyzeResponseForTokensWithLifecycleç»Ÿä¸€å¤„ç†
			return
		}
	}
	
	// If we found an error event, the parseErrorEvent method would have already handled it
	if hasErrorEvent {
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] [%s] ç«¯ç‚¹: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", connID, endpointName))
		return
	}
	
	if !foundTokenUsage {
		slog.InfoContext(ctx, fmt.Sprintf("ğŸš« [SSEè§£æ] [%s] ç«¯ç‚¹: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", connID, endpointName))

		// ğŸ” [è°ƒè¯•] å¼‚æ­¥ä¿å­˜å“åº”æ•°æ®ç”¨äºè°ƒè¯•Tokenè§£æå¤±è´¥é—®é¢˜
		utils.WriteTokenDebugResponse(connID, endpointName, responseBody)
	}
}

// ParseJSONTokens parses single JSON response for token usage
func (a *TokenAnalyzer) ParseJSONTokens(ctx context.Context, responseBody, endpointName, connID string) {
	// Simulate SSE parsing for a single JSON response
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// ğŸ†• First extract model information directly from JSON
	var jsonResp map[string]interface{}
	if err := json.Unmarshal([]byte(responseBody), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			tokenParser.SetModelName(model)
			slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage
		if mm, ok := a.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
	}
}

// AnalyzeResponseForTokensWithLifecycle analyzes response with accurate duration from lifecycle manager
// ğŸ†• [ä¿®å¤] ä½¿ç”¨æ–°çš„ä¸‰å±‚é˜²æŠ¤æ ¼å¼æ£€æµ‹ç³»ç»Ÿï¼Œé¿å…JSONå“åº”è¢«è¯¯åˆ¤ä¸ºSSE
func (a *TokenAnalyzer) AnalyzeResponseForTokensWithLifecycle(ctx context.Context, responseBody, endpointName string, r *http.Request, lifecycleManager RequestLifecycleManager) {
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}

	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚",
		connID, endpointName, len(responseBody)))

	// ğŸ†• [ä¿®å¤] ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼æ£€æµ‹æ›¿ä»£strings.Containsåˆ¤æ–­
	format := detectResponseFormat(responseBody)
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [æ ¼å¼æ£€æµ‹] [%s] å“åº”æ ¼å¼: %s, é•¿åº¦: %d",
		connID, formatName(format), len(responseBody)))

	// ğŸ†• [ä¿®å¤] åŸºäºæ£€æµ‹ç»“æœè¿›è¡Œæ™ºèƒ½è·¯ç”±
	switch format {
	case FormatJSON:
		// âœ… æ˜ç¡®æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨JSONè§£æå™¨
		slog.DebugContext(ctx, fmt.Sprintf("ğŸ” [JSONè·¯ç”±] [%s] æ£€æµ‹ä¸ºJSONæ ¼å¼ï¼Œä½¿ç”¨JSONè§£æå™¨", connID))

		// ä½¿ç”¨ç»Ÿä¸€çš„JSONè§£ææ–¹æ³•
		tokenUsage, modelName := a.parseJSONForTokens(responseBody, connID, endpointName)
		if tokenUsage != nil {
			// Record token usage to monitoring middleware
			if mm, ok := a.monitoringMiddleware.(interface{
				RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
			}); ok && connID != "" {
				// è½¬æ¢ä¸ºmonitor.TokenUsageæ ¼å¼
				monitorTokenUsage := &monitor.TokenUsage{
					InputTokens:         tokenUsage.InputTokens,
					OutputTokens:        tokenUsage.OutputTokens,
					CacheCreationTokens: tokenUsage.CacheCreationTokens,
					CacheReadTokens:     tokenUsage.CacheReadTokens,
				}
				mm.RecordTokenUsage(connID, endpointName, monitorTokenUsage)
				slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨",
					"endpoint", endpointName,
					"inputTokens", tokenUsage.InputTokens,
					"outputTokens", tokenUsage.OutputTokens,
					"cacheCreation", tokenUsage.CacheCreationTokens,
					"cacheRead", tokenUsage.CacheReadTokens)
			}
			slog.InfoContext(ctx, "ğŸ’¾ [JSONæ•°æ®åº“ä¿å­˜] JSONè§£æçš„Tokenä¿¡æ¯å·²è§£æå®Œæˆ",
				"request_id", connID, "model", modelName,
				"inputTokens", tokenUsage.InputTokens, "outputTokens", tokenUsage.OutputTokens)
		} else {
			slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å°†ç”±Handleræ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response", connID))
		}
		return

	case FormatSSE:
		// âœ… æ˜ç¡®æ˜¯SSEï¼Œä½¿ç”¨SSEè§£æå™¨
		slog.DebugContext(ctx, fmt.Sprintf("ğŸŒŠ [SSEè·¯ç”±] [%s] æ£€æµ‹ä¸ºSSEæ ¼å¼ï¼Œä½¿ç”¨SSEè§£æå™¨", connID))
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)

		// ä½¿ç”¨ç»Ÿä¸€çš„SSEè§£ææ–¹æ³•
		tokenUsage, modelName := a.parseSSEForTokens(responseBody, connID, endpointName)
		if tokenUsage != nil {
			slog.InfoContext(ctx, fmt.Sprintf("ğŸ’¾ [SSETokenè§£æ] [%s] æ¨¡å‹: %s, Tokenä¿¡æ¯å·²è§£æå®Œæˆ", connID, modelName))
		}
		return

	default:
		// âš ï¸ [ç¬¬ä¸‰å±‚] æ ¼å¼æœªçŸ¥ï¼Œå¯ç”¨é˜²æŠ¤æ€§å›é€€æœºåˆ¶
		slog.DebugContext(ctx, fmt.Sprintf("â“ [æœªçŸ¥æ ¼å¼] [%s] æ ¼å¼æ£€æµ‹å¤±è´¥ï¼Œå¯ç”¨å›é€€æœºåˆ¶", connID))
		tokenUsage, modelName := a.parseWithFallback(responseBody, connID, endpointName)
		if tokenUsage != nil {
			// å›é€€æœºåˆ¶æˆåŠŸæ‰¾åˆ°Tokenä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [å›é€€æˆåŠŸ] [%s] æ¨¡å‹: %s, Tokenä¿¡æ¯å·²è§£æ", connID, modelName))
		} else {
			// æœ€ç»ˆå¤±è´¥ï¼šæ— Tokenä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å°†ç”±Handleræ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response", connID))
		}
	}
}

// AnalyzeResponseForTokensUnified ç®€åŒ–ç‰ˆæœ¬çš„Tokenåˆ†æï¼ˆç”¨äºç»Ÿä¸€æ¥å£ï¼‰
// è¿”å›å€¼: (tokenUsage, modelName) - tokenUsageä¸ºnilè¡¨ç¤ºæ— Tokenä¿¡æ¯
// ğŸ†• [Pikeæ–¹æ¡ˆ] ä½¿ç”¨ä¸‰å±‚é˜²æŠ¤çš„æ ¼å¼æ£€æµ‹ç³»ç»Ÿ
func (a *TokenAnalyzer) AnalyzeResponseForTokensUnified(responseBytes []byte, connID, endpointName string) (*tracking.TokenUsage, string) {
	if len(responseBytes) == 0 {
		return nil, "empty_response"
	}

	responseStr := string(responseBytes)

	// ğŸ†• [ç¬¬ä¸€å±‚] ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼æ£€æµ‹
	format := detectResponseFormat(responseStr)
	slog.Debug(fmt.Sprintf("ğŸ¯ [æ ¼å¼æ£€æµ‹] [%s] å“åº”æ ¼å¼: %s, é•¿åº¦: %d",
		connID, formatName(format), len(responseStr)))

	// ğŸ†• [ç¬¬äºŒå±‚] åŸºäºæ£€æµ‹ç»“æœè¿›è¡Œæ™ºèƒ½è·¯ç”±
	switch format {
	case FormatJSON:
		// âœ… æ˜ç¡®æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨JSONè§£æå™¨
		slog.Debug(fmt.Sprintf("ğŸ” [JSONè·¯ç”±] [%s] æ£€æµ‹ä¸ºJSONæ ¼å¼ï¼Œä½¿ç”¨JSONè§£æå™¨", connID))
		return a.parseJSONForTokens(responseStr, connID, endpointName)

	case FormatSSE:
		// âœ… æ˜ç¡®æ˜¯SSEï¼Œä½¿ç”¨SSEè§£æå™¨
		slog.Debug(fmt.Sprintf("ğŸŒŠ [SSEè·¯ç”±] [%s] æ£€æµ‹ä¸ºSSEæ ¼å¼ï¼Œä½¿ç”¨SSEè§£æå™¨", connID))
		return a.parseSSEForTokens(responseStr, connID, endpointName)

	default:
		// âš ï¸ [ç¬¬ä¸‰å±‚] æ ¼å¼æœªçŸ¥ï¼Œå¯ç”¨é˜²æŠ¤æ€§å›é€€æœºåˆ¶
		slog.Debug(fmt.Sprintf("â“ [æœªçŸ¥æ ¼å¼] [%s] æ ¼å¼æ£€æµ‹å¤±è´¥ï¼Œå¯ç”¨å›é€€æœºåˆ¶", connID))
		return a.parseWithFallback(responseStr, connID, endpointName)
	}
}

// parseSSEForTokens è§£æSSEæ ¼å¼å“åº”è·å–Tokenä¿¡æ¯ï¼ˆä¸ç›´æ¥è®°å½•ï¼‰
func (a *TokenAnalyzer) parseSSEForTokens(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	lines := strings.Split(responseStr, "\n")
	
	var foundTokenUsage *tracking.TokenUsage
	var modelName string = "unknown"
	hasErrorEvent := false
	
	// æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯äº‹ä»¶
	if strings.Contains(responseStr, "event:error") || strings.Contains(responseStr, "event: error") {
		hasErrorEvent = true
		slog.Info(fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] [%s] ç«¯ç‚¹: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", connID, endpointName))
	}
	
	// è§£ææ¯ä¸€è¡Œ
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			// è·å–æ¨¡å‹åç§°
			if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
				modelName = tp.GetModelName()
			}
			
			// è½¬æ¢ä¸ºtracking.TokenUsageæ ¼å¼
			foundTokenUsage = &tracking.TokenUsage{
				InputTokens:         tokenUsage.InputTokens,
				OutputTokens:        tokenUsage.OutputTokens,
				CacheCreationTokens: tokenUsage.CacheCreationTokens,
				CacheReadTokens:     tokenUsage.CacheReadTokens,
			}
			
			slog.Info(fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] [%s] ç«¯ç‚¹: %s - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d", 
				connID, endpointName, modelName, 
				foundTokenUsage.InputTokens, foundTokenUsage.OutputTokens, 
				foundTokenUsage.CacheCreationTokens, foundTokenUsage.CacheReadTokens))
			
			return foundTokenUsage, modelName
		}
	}
	
	// å¦‚æœæœ‰é”™è¯¯äº‹ä»¶æˆ–æ²¡æ‰¾åˆ°Tokenä¿¡æ¯
	if hasErrorEvent {
		slog.Info(fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] [%s] ç«¯ç‚¹: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", connID, endpointName))
		return nil, "error_response"
	}
	
	slog.Info(fmt.Sprintf("ğŸš« [SSEè§£æ] [%s] ç«¯ç‚¹: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", connID, endpointName))

	// ğŸ” [è°ƒè¯•] å¼‚æ­¥ä¿å­˜å“åº”æ•°æ®ç”¨äºè°ƒè¯•Tokenè§£æå¤±è´¥é—®é¢˜
	utils.WriteTokenDebugResponse(connID, endpointName, responseStr)

	return nil, "no_token_sse"
}

// parseJSONForTokens è§£æJSONæ ¼å¼å“åº”è·å–Tokenä¿¡æ¯ï¼ˆä¸ç›´æ¥è®°å½•ï¼‰
func (a *TokenAnalyzer) parseJSONForTokens(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	
	slog.Info(fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// é¦–å…ˆæå–æ¨¡å‹ä¿¡æ¯
	var jsonResp map[string]interface{}
	var modelName string = "default"
	
	if err := json.Unmarshal([]byte(responseStr), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			modelName = model
			tokenParser.SetModelName(model)
			slog.Info("ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// å°†JSONåŒ…è£…ä¸ºSSE message_deltaäº‹ä»¶è¿›è¡Œè§£æ
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseStr)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// è½¬æ¢ä¸ºtracking.TokenUsageæ ¼å¼
		trackingTokenUsage := &tracking.TokenUsage{
			InputTokens:         tokenUsage.InputTokens,
			OutputTokens:        tokenUsage.OutputTokens,
			CacheCreationTokens: tokenUsage.CacheCreationTokens,
			CacheReadTokens:     tokenUsage.CacheReadTokens,
		}
		
		slog.Info("âœ… [JSONè§£æ] æˆåŠŸè§£æTokenä½¿ç”¨ä¿¡æ¯", 
			"endpoint", endpointName, 
			"inputTokens", trackingTokenUsage.InputTokens, 
			"outputTokens", trackingTokenUsage.OutputTokens,
			"cacheCreation", trackingTokenUsage.CacheCreationTokens,
			"cacheRead", trackingTokenUsage.CacheReadTokens)
		
		return trackingTokenUsage, modelName
	}
	
	slog.Debug(fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))

	// ğŸ” [è°ƒè¯•] å¼‚æ­¥ä¿å­˜å“åº”æ•°æ®ç”¨äºè°ƒè¯•Tokenè§£æå¤±è´¥é—®é¢˜
	utils.WriteTokenDebugResponse(connID, endpointName, responseStr)

	return nil, modelName
}

// ============================================================================
// ğŸ”§ [Pikeæ–¹æ¡ˆ] ä¸‰å±‚é˜²æŠ¤çš„æ ¼å¼æ£€æµ‹ç³»ç»Ÿ
// ============================================================================

// formatName è¿”å›æ ¼å¼ç±»å‹çš„å¯è¯»åç§°
func formatName(format ResponseFormat) string {
	switch format {
	case FormatJSON:
		return "JSON"
	case FormatSSE:
		return "SSE"
	case FormatPlainText:
		return "PlainText"
	default:
		return "Unknown"
	}
}

// detectResponseFormat æ™ºèƒ½æ£€æµ‹å“åº”æ ¼å¼ï¼ˆç¬¬ä¸€å±‚ï¼šç»“æ„åŒ–æ£€æµ‹ï¼‰
// åŸºäºå“åº”çš„å®é™…ç»“æ„è€Œéå†…å®¹è¿›è¡Œåˆ¤æ–­ï¼Œé¿å…è¢«JSONä¸­çš„å­—ç¬¦ä¸²å†…å®¹è¯¯å¯¼
func detectResponseFormat(response string) ResponseFormat {
	trimmed := strings.TrimSpace(response)
	if len(trimmed) == 0 {
		return FormatUnknown
	}

	// 1ï¸âƒ£ JSONä¼˜å…ˆæ£€æµ‹ - åŸºäºç»“æ„è€Œéå†…å®¹
	if isValidJSONStructure(trimmed) {
		return FormatJSON
	}

	// 2ï¸âƒ£ SSEè§„èŒƒæ£€æµ‹ - åŸºäºåè®®ç»“æ„
	if isValidSSEStructure(trimmed) {
		return FormatSSE
	}

	// 3ï¸âƒ£ å…¶ä»–æ ¼å¼
	return FormatUnknown
}

// isValidJSONStructure ä¸¥æ ¼çš„JSONç»“æ„éªŒè¯
// ä¸ä¾èµ–å†…å®¹ï¼ŒåªéªŒè¯æ˜¯å¦ç¬¦åˆJSONæ ¼å¼è§„èŒƒ
func isValidJSONStructure(content string) bool {
	// å¿«é€Ÿç»“æ„æ£€æŸ¥
	if !strings.HasPrefix(content, "{") || !strings.HasSuffix(content, "}") {
		return false
	}

	// ä¸¥æ ¼éªŒè¯ï¼šå°è¯•è§£æJSONç»“æ„
	var temp map[string]interface{}
	return json.Unmarshal([]byte(content), &temp) == nil
}

// isValidSSEStructure ä¸¥æ ¼çš„SSEç»“æ„éªŒè¯
// éªŒè¯æ˜¯å¦ç¬¦åˆServer-Sent Eventsè§„èŒƒç»“æ„ï¼Œè€Œéç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
func isValidSSEStructure(content string) bool {
	lines := strings.Split(content, "\n")
	hasEventOrData := false
	validSSELines := 0
	totalNonEmptyLines := 0

	for _, line := range lines {
		originalLine := line
		line = strings.TrimSpace(line)

		// ç©ºè¡Œæ˜¯SSEè§„èŒƒçš„ä¸€éƒ¨åˆ†ï¼Œè·³è¿‡
		if line == "" {
			continue
		}

		totalNonEmptyLines++

		// çœŸæ­£çš„SSEè¡Œå¿…é¡»ä»¥event:æˆ–data:å¼€å¤´ï¼ˆè¡Œé¦–æ£€æŸ¥ï¼‰
		if strings.HasPrefix(originalLine, "event:") || strings.HasPrefix(originalLine, "data:") {
			hasEventOrData = true
			validSSELines++
		} else {
			// å‘ç°ä¸ç¬¦åˆSSEæ ¼å¼çš„è¡Œï¼Œå¯èƒ½æ˜¯JSONä¸­çš„å†…å®¹
			// å¦‚æœå¤§éƒ¨åˆ†è¡Œéƒ½ä¸ç¬¦åˆSSEæ ¼å¼ï¼Œåˆ™è®¤ä¸ºè¿™ä¸æ˜¯çœŸæ­£çš„SSEå“åº”
			continue
		}
	}

	// å¿…é¡»æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶ï¼š
	// 1. è‡³å°‘æœ‰ä¸€ä¸ªeventæˆ–dataè¡Œ
	// 2. SSEæ ¼å¼è¡Œå æ¯”è¶…è¿‡50%ï¼ˆé˜²æ­¢JSONä¸­å¶ç„¶åŒ…å«SSEå…³é”®å­—ï¼‰
	if !hasEventOrData || totalNonEmptyLines == 0 {
		return false
	}

	sseRatio := float64(validSSELines) / float64(totalNonEmptyLines)
	return sseRatio > 0.5 // SSEæ ¼å¼è¡Œå æ¯”è¶…è¿‡50%æ‰è®¤ä¸ºæ˜¯çœŸæ­£çš„SSE
}

// ============================================================================
// ğŸ›¡ï¸ [Pikeæ–¹æ¡ˆ] é˜²æŠ¤æ€§å›é€€æœºåˆ¶ï¼ˆç¬¬ä¸‰å±‚ï¼šå…œåº•å¤„ç†ï¼‰
// ============================================================================

// parseWithFallback å½“ç»“æ„åŒ–æ£€æµ‹ä¹Ÿå¤±è´¥æ—¶çš„æœ€åé˜²çº¿
func (a *TokenAnalyzer) parseWithFallback(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	slog.Debug(fmt.Sprintf("ğŸ›¡ï¸ [å›é€€æœºåˆ¶] [%s] å¯åŠ¨å…œåº•è§£æ", connID))

	// å°è¯•1: å¼ºåˆ¶JSONè§£æï¼ˆå¿½ç•¥ç»“æ„éªŒè¯ï¼‰
	if tokenUsage, model := a.tryForceJSONParse(responseStr, connID, endpointName); tokenUsage != nil {
		slog.Info(fmt.Sprintf("âœ… [å›é€€æˆåŠŸ] [%s] å¼ºåˆ¶JSONè§£ææˆåŠŸ", connID))
		return tokenUsage, model
	}

	// å°è¯•2: å®½æ¾SSEè§£æï¼ˆé™ä½éªŒè¯æ ‡å‡†ï¼‰
	if tokenUsage, model := a.tryLenientSSEParse(responseStr, connID, endpointName); tokenUsage != nil {
		slog.Info(fmt.Sprintf("âœ… [å›é€€æˆåŠŸ] [%s] å®½æ¾SSEè§£ææˆåŠŸ", connID))
		return tokenUsage, model
	}

	// æœ€ç»ˆå¤±è´¥
	slog.Info(fmt.Sprintf("ğŸ¯ [å›é€€å¤±è´¥] [%s] ç«¯ç‚¹: %s - æ‰€æœ‰è§£ææ–¹æ³•å‡å¤±è´¥", connID, endpointName))
	return nil, "non_token_response"
}

// tryForceJSONParse å¼ºåˆ¶å°è¯•JSONè§£æï¼ˆå¿½ç•¥ç»“æ„éªŒè¯ï¼‰
func (a *TokenAnalyzer) tryForceJSONParse(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	// å¦‚æœå“åº”åŒ…å«usageå­—æ®µï¼Œå¼ºåˆ¶æŒ‰JSONè§£æ
	if strings.Contains(responseStr, "\"usage\"") {
		slog.Debug(fmt.Sprintf("ğŸ” [å¼ºåˆ¶JSON] [%s] å‘ç°usageå­—æ®µï¼Œå¼ºåˆ¶JSONè§£æ", connID))
		return a.parseJSONForTokens(responseStr, connID, endpointName)
	}
	return nil, ""
}

// tryLenientSSEParse å®½æ¾çš„SSEè§£æï¼ˆé™ä½éªŒè¯æ ‡å‡†ï¼‰
func (a *TokenAnalyzer) tryLenientSSEParse(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	// å®½æ¾æ¡ä»¶ï¼šåªè¦åŒ…å«ä»»ä½•eventæˆ–dataè¡Œå°±å°è¯•è§£æ
	if strings.Contains(responseStr, "event:") || strings.Contains(responseStr, "data:") {
		slog.Debug(fmt.Sprintf("ğŸŒŠ [å®½æ¾SSE] [%s] å‘ç°SSEå…³é”®å­—ï¼Œå°è¯•å®½æ¾è§£æ", connID))
		return a.parseSSEForTokens(responseStr, connID, endpointName)
	}
	return nil, ""
}