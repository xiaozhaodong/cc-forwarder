package response

import (
	"context"
	"encoding/json"
	"fmt"
	"log/slog"
	"net/http"
	"strings"
	"time"

	"cc-forwarder/internal/monitor"
	"cc-forwarder/internal/tracking"
)

// RequestLifecycleManager å®šä¹‰ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¥å£
type RequestLifecycleManager interface {
	GetDuration() time.Duration
}

// TokenParser å®šä¹‰token parseræ¥å£
type TokenParser interface {
	ParseSSELine(line string) *monitor.TokenUsage
	SetModelName(model string)
}

// TokenParserProvider æä¾›token parseråˆ›å»ºåŠŸèƒ½
type TokenParserProvider interface {
	NewTokenParser() TokenParser
	NewTokenParserWithUsageTracker(requestID string, usageTracker *tracking.UsageTracker) TokenParser
}

// TokenAnalyzer è´Ÿè´£åˆ†æå“åº”ä¸­çš„Tokenä½¿ç”¨ä¿¡æ¯
type TokenAnalyzer struct {
	usageTracker         *tracking.UsageTracker
	monitoringMiddleware interface{}
	tokenParserProvider  TokenParserProvider
}

// NewTokenAnalyzer åˆ›å»ºæ–°çš„TokenAnalyzerå®ä¾‹
func NewTokenAnalyzer(usageTracker *tracking.UsageTracker, monitoringMiddleware interface{}, provider TokenParserProvider) *TokenAnalyzer {
	return &TokenAnalyzer{
		usageTracker:         usageTracker,
		monitoringMiddleware: monitoringMiddleware,
		tokenParserProvider:  provider,
	}
}

// AnalyzeResponseForTokens analyzes the complete response body for token usage information
func (a *TokenAnalyzer) AnalyzeResponseForTokens(ctx context.Context, responseBody, endpointName string, r *http.Request) {
	
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event:message_delta") || 
	   strings.Contains(responseBody, "event: message_delta") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Method 2: Try to parse as single JSON response
	if strings.HasPrefix(strings.TrimSpace(responseBody), "{") && strings.Contains(responseBody, "usage") {
		a.ParseJSONTokens(ctx, responseBody, endpointName, connID)
		return
	}

	// Fallback: No token information found, mark request as completed with non_token_response model
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ¯ [æ— Tokenå“åº”] ç«¯ç‚¹: %s, è¿æ¥: %s - å“åº”ä¸åŒ…å«tokenä¿¡æ¯ï¼Œæ ‡è®°ä¸ºå®Œæˆ", endpointName, connID))
	
	// âš ï¸ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¸å†ç›´æ¥è®°å½•åˆ°æ•°æ®åº“ï¼Œç”±è°ƒç”¨æ–¹å†³å®šå¦‚ä½•å¤„ç†
	// ä½†ä¸ºäº†å…¼å®¹ç°æœ‰è°ƒç”¨ï¼Œæˆ‘ä»¬ä¿ç•™æ—¥å¿—è®°å½•åŠŸèƒ½
	if connID != "" {
		slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s æ£€æµ‹ä¸ºæ— Tokenå“åº”ï¼Œæ¨¡å‹: non_token_response", connID))
	}
}

// ParseSSETokens parses SSE format response for token usage or error events
func (a *TokenAnalyzer) ParseSSETokens(ctx context.Context, responseBody, endpointName, connID string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	lines := strings.Split(responseBody, "\n")
	
	foundTokenUsage := false
	hasErrorEvent := false
	
	// Check if response contains error events first
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		hasErrorEvent = true
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] [%s] ç«¯ç‚¹: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", connID, endpointName))
	}
	
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			foundTokenUsage = true
			// è·å–æ¨¡å‹åç§°(éœ€è¦ç±»å‹æ–­è¨€è·å–TokenParserçš„æ¨¡å‹ä¿¡æ¯)
			modelName := "unknown"
			if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
				modelName = tp.GetModelName()
			}
			
			// è¯¦ç»†æ˜¾ç¤ºtokenä½¿ç”¨ä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] [%s] ç«¯ç‚¹: %s - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d", 
				connID, endpointName, modelName, 
				tokenUsage.InputTokens, tokenUsage.OutputTokens, 
				tokenUsage.CacheCreationTokens, tokenUsage.CacheReadTokens))
			
			// Record token usage in monitoring middleware if available
			if mm, ok := a.monitoringMiddleware.(interface{
				RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
			}); ok && connID != "" {
				mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			}
			
			// âš ï¸ é‡è¦ï¼šTokenParserç°åœ¨åªè´Ÿè´£è§£æï¼Œä¸ç›´æ¥è®°å½•åˆ°æ•°æ®åº“
			// æ•°æ®åº“è®°å½•ç”±ä¸Šå±‚AnalyzeResponseForTokensWithLifecycleç»Ÿä¸€å¤„ç†
			return
		}
	}
	
	// If we found an error event, the parseErrorEvent method would have already handled it
	if hasErrorEvent {
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] [%s] ç«¯ç‚¹: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", connID, endpointName))
		return
	}
	
	if !foundTokenUsage {
		slog.InfoContext(ctx, fmt.Sprintf("ğŸš« [SSEè§£æ] [%s] ç«¯ç‚¹: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", connID, endpointName))
	}
}

// ParseJSONTokens parses single JSON response for token usage
func (a *TokenAnalyzer) ParseJSONTokens(ctx context.Context, responseBody, endpointName, connID string) {
	// Simulate SSE parsing for a single JSON response
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// ğŸ†• First extract model information directly from JSON
	var jsonResp map[string]interface{}
	if err := json.Unmarshal([]byte(responseBody), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			tokenParser.SetModelName(model)
			slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage
		if mm, ok := a.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
	}
}

// AnalyzeResponseForTokensWithLifecycle analyzes response with accurate duration from lifecycle manager
func (a *TokenAnalyzer) AnalyzeResponseForTokensWithLifecycle(ctx context.Context, responseBody, endpointName string, r *http.Request, lifecycleManager RequestLifecycleManager) {
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event:message_delta") ||
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event: message_delta") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		
		// â„¹ï¸ è¿”å›Tokenä¿¡æ¯ï¼Œç”±Handleré€šè¿‡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•
		// ä¸å†ç›´æ¥è°ƒç”¨usageTracker.RecordRequestCompleteï¼Œéµå¾ªæ¶æ„åŸåˆ™
		if tokenUsage, modelName := a.parseSSEForTokens(responseBody, connID, endpointName); tokenUsage != nil {
			slog.InfoContext(ctx, fmt.Sprintf("ğŸ’¾ [SSETokenè§£æ] [%s] æ¨¡å‹: %s, Tokenä¿¡æ¯å·²è§£æå®Œæˆ", connID, modelName))
			// è¿”å›Tokenä¿¡æ¯ï¼Œç”±ä¸Šå±‚Handlerè°ƒç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•
			return // TokenAnalyzerä¸å†ç›´æ¥è®°å½•ï¼Œè¿”å›ç»™ä¸Šå±‚å¤„ç†
		}
		
		return
	}
	
	// Method 2: Direct JSON analysis for non-SSE responses
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// Try to parse as JSON and extract model information
	var jsonData map[string]interface{}
	var model string
	
	if err := json.Unmarshal([]byte(responseBody), &jsonData); err == nil {
		// Extract model information if available
		if modelValue, exists := jsonData["model"]; exists {
			if modelStr, ok := modelValue.(string); ok {
				model = modelStr
				slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
			}
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser := a.tokenParserProvider.NewTokenParser()
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage to monitoring middleware
		if mm, ok := a.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
		
		// â„¹ï¸ è¿”å›Tokenä¿¡æ¯ï¼Œç”±Handleré€šè¿‡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•
		// ä¸å†ç›´æ¥è°ƒç”¨usageTracker.RecordRequestCompleteï¼Œéµå¾ªæ¶æ„åŸåˆ™
		if tokenUsage, modelName := a.parseJSONForTokens(responseBody, connID, endpointName); tokenUsage != nil {
			slog.InfoContext(ctx, "ğŸ’¾ [JSONæ•°æ®åº“ä¿å­˜] JSONè§£æçš„Tokenä¿¡æ¯å·²è§£æå®Œæˆ",
				"request_id", connID, "model", modelName, 
				"inputTokens", tokenUsage.InputTokens, "outputTokens", tokenUsage.OutputTokens)
			// TokenAnalyzerä¸å†ç›´æ¥è®°å½•ï¼Œè¿”å›ç»™ä¸Šå±‚å¤„ç†
		} else {
			slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
			
			// â„¹ï¸ Fallback: è¿”å›ç©ºçš„Tokenä¿¡æ¯ï¼Œç”±Handleré€šè¿‡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è®°å½•
			// ä¸å†ç›´æ¥è°ƒç”¨usageTracker.RecordRequestCompleteï¼Œéµå¾ªæ¶æ„åŸåˆ™
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å°†ç”±Handleræ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response", connID))
		}
	}
}

// AnalyzeResponseForTokensUnified ç®€åŒ–ç‰ˆæœ¬çš„Tokenåˆ†æï¼ˆç”¨äºç»Ÿä¸€æ¥å£ï¼‰
// è¿”å›å€¼: (tokenUsage, modelName) - tokenUsageä¸ºnilè¡¨ç¤ºæ— Tokenä¿¡æ¯
func (a *TokenAnalyzer) AnalyzeResponseForTokensUnified(responseBytes []byte, connID, endpointName string) (*tracking.TokenUsage, string) {
	if len(responseBytes) == 0 {
		return nil, "empty_response"
	}
	
	responseStr := string(responseBytes)
	
	// Method 1: æ£€æŸ¥æ˜¯å¦ä¸ºSSEæ ¼å¼å“åº”
	if strings.Contains(responseStr, "event:error") || strings.Contains(responseStr, "event: error") {
		return a.parseSSEForTokens(responseStr, connID, endpointName)
	}
	
	// Check for both message_start and message_delta events
	if strings.Contains(responseStr, "event:message_start") || 
	   strings.Contains(responseStr, "event: message_start") ||
	   strings.Contains(responseStr, "event:message_delta") || 
	   strings.Contains(responseStr, "event: message_delta") {
		return a.parseSSEForTokens(responseStr, connID, endpointName)
	}
	
	// Method 2: å°è¯•è§£æJSONå“åº”
	if strings.HasPrefix(strings.TrimSpace(responseStr), "{") && strings.Contains(responseStr, "usage") {
		return a.parseJSONForTokens(responseStr, connID, endpointName)
	}
	
	// Fallback: æ— Tokenä¿¡æ¯
	slog.Info(fmt.Sprintf("ğŸ¯ [æ— Tokenå“åº”] ç«¯ç‚¹: %s, è¿æ¥: %s - å“åº”ä¸åŒ…å«tokenä¿¡æ¯", endpointName, connID))
	return nil, "non_token_response"
}

// parseSSEForTokens è§£æSSEæ ¼å¼å“åº”è·å–Tokenä¿¡æ¯ï¼ˆä¸ç›´æ¥è®°å½•ï¼‰
func (a *TokenAnalyzer) parseSSEForTokens(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	lines := strings.Split(responseStr, "\n")
	
	var foundTokenUsage *tracking.TokenUsage
	var modelName string = "unknown"
	hasErrorEvent := false
	
	// æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯äº‹ä»¶
	if strings.Contains(responseStr, "event:error") || strings.Contains(responseStr, "event: error") {
		hasErrorEvent = true
		slog.Info(fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] [%s] ç«¯ç‚¹: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", connID, endpointName))
	}
	
	// è§£ææ¯ä¸€è¡Œ
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			// è·å–æ¨¡å‹åç§°
			if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
				modelName = tp.GetModelName()
			}
			
			// è½¬æ¢ä¸ºtracking.TokenUsageæ ¼å¼
			foundTokenUsage = &tracking.TokenUsage{
				InputTokens:         tokenUsage.InputTokens,
				OutputTokens:        tokenUsage.OutputTokens,
				CacheCreationTokens: tokenUsage.CacheCreationTokens,
				CacheReadTokens:     tokenUsage.CacheReadTokens,
			}
			
			slog.Info(fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] [%s] ç«¯ç‚¹: %s - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d", 
				connID, endpointName, modelName, 
				foundTokenUsage.InputTokens, foundTokenUsage.OutputTokens, 
				foundTokenUsage.CacheCreationTokens, foundTokenUsage.CacheReadTokens))
			
			return foundTokenUsage, modelName
		}
	}
	
	// å¦‚æœæœ‰é”™è¯¯äº‹ä»¶æˆ–æ²¡æ‰¾åˆ°Tokenä¿¡æ¯
	if hasErrorEvent {
		slog.Info(fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] [%s] ç«¯ç‚¹: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", connID, endpointName))
		return nil, "error_response"
	}
	
	slog.Info(fmt.Sprintf("ğŸš« [SSEè§£æ] [%s] ç«¯ç‚¹: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", connID, endpointName))
	return nil, "no_token_sse"
}

// parseJSONForTokens è§£æJSONæ ¼å¼å“åº”è·å–Tokenä¿¡æ¯ï¼ˆä¸ç›´æ¥è®°å½•ï¼‰
func (a *TokenAnalyzer) parseJSONForTokens(responseStr, connID, endpointName string) (*tracking.TokenUsage, string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	
	slog.Info(fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// é¦–å…ˆæå–æ¨¡å‹ä¿¡æ¯
	var jsonResp map[string]interface{}
	var modelName string = "default"
	
	if err := json.Unmarshal([]byte(responseStr), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			modelName = model
			tokenParser.SetModelName(model)
			slog.Info("ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// å°†JSONåŒ…è£…ä¸ºSSE message_deltaäº‹ä»¶è¿›è¡Œè§£æ
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseStr)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// è½¬æ¢ä¸ºtracking.TokenUsageæ ¼å¼
		trackingTokenUsage := &tracking.TokenUsage{
			InputTokens:         tokenUsage.InputTokens,
			OutputTokens:        tokenUsage.OutputTokens,
			CacheCreationTokens: tokenUsage.CacheCreationTokens,
			CacheReadTokens:     tokenUsage.CacheReadTokens,
		}
		
		slog.Info("âœ… [JSONè§£æ] æˆåŠŸè§£æTokenä½¿ç”¨ä¿¡æ¯", 
			"endpoint", endpointName, 
			"inputTokens", trackingTokenUsage.InputTokens, 
			"outputTokens", trackingTokenUsage.OutputTokens,
			"cacheCreation", trackingTokenUsage.CacheCreationTokens,
			"cacheRead", trackingTokenUsage.CacheReadTokens)
		
		return trackingTokenUsage, modelName
	}
	
	slog.Debug(fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
	return nil, modelName
}