package response

import (
	"context"
	"encoding/json"
	"fmt"
	"log/slog"
	"net/http"
	"strings"
	"time"

	"cc-forwarder/internal/monitor"
	"cc-forwarder/internal/tracking"
)

// RequestLifecycleManager å®šä¹‰ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¥å£
type RequestLifecycleManager interface {
	GetDuration() time.Duration
}

// TokenParser å®šä¹‰token parseræ¥å£
type TokenParser interface {
	ParseSSELine(line string) *monitor.TokenUsage
	SetModelName(model string)
}

// TokenParserProvider æä¾›token parseråˆ›å»ºåŠŸèƒ½
type TokenParserProvider interface {
	NewTokenParser() TokenParser
	NewTokenParserWithUsageTracker(requestID string, usageTracker *tracking.UsageTracker) TokenParser
}

// TokenAnalyzer è´Ÿè´£åˆ†æå“åº”ä¸­çš„Tokenä½¿ç”¨ä¿¡æ¯
type TokenAnalyzer struct {
	usageTracker         *tracking.UsageTracker
	monitoringMiddleware interface{}
	tokenParserProvider  TokenParserProvider
}

// NewTokenAnalyzer åˆ›å»ºæ–°çš„TokenAnalyzerå®ä¾‹
func NewTokenAnalyzer(usageTracker *tracking.UsageTracker, monitoringMiddleware interface{}, provider TokenParserProvider) *TokenAnalyzer {
	return &TokenAnalyzer{
		usageTracker:         usageTracker,
		monitoringMiddleware: monitoringMiddleware,
		tokenParserProvider:  provider,
	}
}

// AnalyzeResponseForTokens analyzes the complete response body for token usage information
func (a *TokenAnalyzer) AnalyzeResponseForTokens(ctx context.Context, responseBody, endpointName string, r *http.Request) {
	
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event:message_delta") || 
	   strings.Contains(responseBody, "event: message_delta") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Method 2: Try to parse as single JSON response
	if strings.HasPrefix(strings.TrimSpace(responseBody), "{") && strings.Contains(responseBody, "usage") {
		a.ParseJSONTokens(ctx, responseBody, endpointName, connID)
		return
	}

	// Fallback: No token information found, mark request as completed with non_token_response model
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ¯ [æ— Tokenå“åº”] ç«¯ç‚¹: %s, è¿æ¥: %s - å“åº”ä¸åŒ…å«tokenä¿¡æ¯ï¼Œæ ‡è®°ä¸ºå®Œæˆ", endpointName, connID))
	
	// Update request status to completed and set model name to "non_token_response"
	if a.usageTracker != nil && connID != "" {
		// Create empty token usage for consistent completion tracking
		emptyTokens := &tracking.TokenUsage{
			InputTokens:         0,
			OutputTokens:        0,
			CacheCreationTokens: 0,
			CacheReadTokens:     0,
		}
		
		// Record completion with non_token_response model name and zero duration (since we don't track start time here)
		a.usageTracker.RecordRequestComplete(connID, "non_token_response", emptyTokens, 0)
		
		slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å·²æ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response", connID))
	}
}

// ParseSSETokens parses SSE format response for token usage or error events
func (a *TokenAnalyzer) ParseSSETokens(ctx context.Context, responseBody, endpointName, connID string) {
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	lines := strings.Split(responseBody, "\n")
	
	foundTokenUsage := false
	hasErrorEvent := false
	
	// Check if response contains error events first
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		hasErrorEvent = true
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯æ£€æµ‹] [%s] ç«¯ç‚¹: %s - æ£€æµ‹åˆ°erroräº‹ä»¶", connID, endpointName))
	}
	
	for _, line := range lines {
		if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
			foundTokenUsage = true
			// è·å–æ¨¡å‹åç§°(éœ€è¦ç±»å‹æ–­è¨€è·å–TokenParserçš„æ¨¡å‹ä¿¡æ¯)
			modelName := "unknown"
			if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
				modelName = tp.GetModelName()
			}
			
			// è¯¦ç»†æ˜¾ç¤ºtokenä½¿ç”¨ä¿¡æ¯
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [SSEè§£ææˆåŠŸ] [%s] ç«¯ç‚¹: %s - æ¨¡å‹: %s, è¾“å…¥: %d, è¾“å‡º: %d, ç¼“å­˜åˆ›å»º: %d, ç¼“å­˜è¯»å–: %d", 
				connID, endpointName, modelName, 
				tokenUsage.InputTokens, tokenUsage.OutputTokens, 
				tokenUsage.CacheCreationTokens, tokenUsage.CacheReadTokens))
			
			// Record token usage in monitoring middleware if available
			if mm, ok := a.monitoringMiddleware.(interface{
				RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
			}); ok && connID != "" {
				mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			}
			
			// âš ï¸ é‡è¦ï¼šTokenParserç°åœ¨åªè´Ÿè´£è§£æï¼Œä¸ç›´æ¥è®°å½•åˆ°æ•°æ®åº“
			// æ•°æ®åº“è®°å½•ç”±ä¸Šå±‚AnalyzeResponseForTokensWithLifecycleç»Ÿä¸€å¤„ç†
			return
		}
	}
	
	// If we found an error event, the parseErrorEvent method would have already handled it
	if hasErrorEvent {
		slog.InfoContext(ctx, fmt.Sprintf("âŒ [SSEé”™è¯¯å¤„ç†] [%s] ç«¯ç‚¹: %s - é”™è¯¯äº‹ä»¶å·²å¤„ç†", connID, endpointName))
		return
	}
	
	if !foundTokenUsage {
		slog.InfoContext(ctx, fmt.Sprintf("ğŸš« [SSEè§£æ] [%s] ç«¯ç‚¹: %s - æœªæ‰¾åˆ°token usageä¿¡æ¯", connID, endpointName))
	}
}

// ParseJSONTokens parses single JSON response for token usage
func (a *TokenAnalyzer) ParseJSONTokens(ctx context.Context, responseBody, endpointName, connID string) {
	// Simulate SSE parsing for a single JSON response
	tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
	
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// ğŸ†• First extract model information directly from JSON
	var jsonResp map[string]interface{}
	if err := json.Unmarshal([]byte(responseBody), &jsonResp); err == nil {
		if model, ok := jsonResp["model"].(string); ok && model != "" {
			tokenParser.SetModelName(model)
			slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage
		if mm, ok := a.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
	}
}

// AnalyzeResponseForTokensWithLifecycle analyzes response with accurate duration from lifecycle manager
func (a *TokenAnalyzer) AnalyzeResponseForTokensWithLifecycle(ctx context.Context, responseBody, endpointName string, r *http.Request, lifecycleManager RequestLifecycleManager) {
	// Get connection ID from request context
	connID := ""
	if connIDValue, ok := r.Context().Value("conn_id").(string); ok {
		connID = connIDValue
	}
	
	// Add entry log for debugging
	slog.DebugContext(ctx, fmt.Sprintf("ğŸ¯ [Tokenåˆ†æå…¥å£] [%s] ç«¯ç‚¹: %s, å“åº”é•¿åº¦: %då­—èŠ‚", 
		connID, endpointName, len(responseBody)))
	
	// Method 1: Try to find SSE format in the response (for streaming responses that were buffered)
	// Check for error events first before checking for token events
	if strings.Contains(responseBody, "event:error") || strings.Contains(responseBody, "event: error") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		return
	}
	
	// Check for both message_start and message_delta events as token info can be in either
	if strings.Contains(responseBody, "event:message_start") || 
	   strings.Contains(responseBody, "event:message_delta") ||
	   strings.Contains(responseBody, "event: message_start") ||
	   strings.Contains(responseBody, "event: message_delta") {
		a.ParseSSETokens(ctx, responseBody, endpointName, connID)
		
		// âš ï¸ è¡¥å……ï¼šParseSSETokensä¸å†è®°å½•åˆ°æ•°æ®åº“ï¼Œéœ€è¦åœ¨æ­¤å¤„è¡¥å……
		// é‡æ–°è§£æè·å–tokenä¿¡æ¯å¹¶è®°å½•åˆ°UsageTracker
		if a.usageTracker != nil && connID != "" {
			tokenParser := a.tokenParserProvider.NewTokenParserWithUsageTracker(connID, a.usageTracker)
			lines := strings.Split(responseBody, "\n")
			
			for _, line := range lines {
				if tokenUsage := tokenParser.ParseSSELine(line); tokenUsage != nil {
					// è·å–æ¨¡å‹åç§°
					modelName := "unknown"
					if tp, ok := tokenParser.(interface{ GetModelName() string }); ok {
						modelName = tp.GetModelName()
					}
					
					// è½¬æ¢ä¸ºtracking.TokenUsageæ ¼å¼
					trackingTokens := &tracking.TokenUsage{
						InputTokens:         tokenUsage.InputTokens,
						OutputTokens:        tokenUsage.OutputTokens,
						CacheCreationTokens: tokenUsage.CacheCreationTokens,
						CacheReadTokens:     tokenUsage.CacheReadTokens,
					}
					
					// è·å–å‡†ç¡®çš„æŒç»­æ—¶é—´
					duration := lifecycleManager.GetDuration()
					
					// è®°å½•åˆ°æ•°æ®åº“
					a.usageTracker.RecordRequestComplete(connID, modelName, trackingTokens, duration)
					break // æ‰¾åˆ°token usageåé€€å‡ºå¾ªç¯
				}
			}
		}
		
		return
	}
	
	// Method 2: Direct JSON analysis for non-SSE responses
	slog.InfoContext(ctx, fmt.Sprintf("ğŸ” [JSONè§£æ] [%s] å°è¯•è§£æJSONå“åº”", connID))
	
	// Try to parse as JSON and extract model information
	var jsonData map[string]interface{}
	var model string
	
	if err := json.Unmarshal([]byte(responseBody), &jsonData); err == nil {
		// Extract model information if available
		if modelValue, exists := jsonData["model"]; exists {
			if modelStr, ok := modelValue.(string); ok {
				model = modelStr
				slog.InfoContext(ctx, "ğŸ“‹ [JSONè§£æ] æå–åˆ°æ¨¡å‹ä¿¡æ¯", "model", model)
			}
		}
	}
	
	// Wrap JSON as SSE message_delta event
	tokenParser := a.tokenParserProvider.NewTokenParser()
	tokenParser.ParseSSELine("event: message_delta")
	tokenParser.ParseSSELine("data: " + responseBody)
	if tokenUsage := tokenParser.ParseSSELine(""); tokenUsage != nil {
		// Record token usage to monitoring middleware
		if mm, ok := a.monitoringMiddleware.(interface{
			RecordTokenUsage(connID string, endpoint string, tokens *monitor.TokenUsage)
		}); ok && connID != "" {
			mm.RecordTokenUsage(connID, endpointName, tokenUsage)
			slog.InfoContext(ctx, "âœ… [JSONè§£æ] æˆåŠŸè®°å½•tokenä½¿ç”¨", 
				"endpoint", endpointName, 
				"inputTokens", tokenUsage.InputTokens, 
				"outputTokens", tokenUsage.OutputTokens,
				"cacheCreation", tokenUsage.CacheCreationTokens,
				"cacheRead", tokenUsage.CacheReadTokens)
		}
		
		// ğŸ”§ ä¿®å¤ï¼šåŒæ—¶ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä½¿ç”¨å‡†ç¡®çš„å¤„ç†æ—¶é—´
		if a.usageTracker != nil && connID != "" && lifecycleManager != nil {
			// è½¬æ¢Tokenæ ¼å¼
			dbTokens := &tracking.TokenUsage{
				InputTokens:         tokenUsage.InputTokens,
				OutputTokens:        tokenUsage.OutputTokens,
				CacheCreationTokens: tokenUsage.CacheCreationTokens,
				CacheReadTokens:     tokenUsage.CacheReadTokens,
			}
			
			// ä½¿ç”¨æå–çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨default
			modelName := "default"
			if model != "" {
				modelName = model
			}
			
			// ğŸ¯ ä½¿ç”¨lifecycleManagerè·å–å‡†ç¡®çš„å¤„ç†æ—¶é—´
			duration := lifecycleManager.GetDuration()
			
			// ä¿å­˜åˆ°æ•°æ®åº“
			a.usageTracker.RecordRequestComplete(connID, modelName, dbTokens, duration)
			slog.InfoContext(ctx, "ğŸ’¾ [æ•°æ®åº“ä¿å­˜] JSONè§£æçš„Tokenä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“",
				"request_id", connID, "model", modelName, 
				"inputTokens", dbTokens.InputTokens, "outputTokens", dbTokens.OutputTokens,
				"duration", duration)
		}
	} else {
		slog.DebugContext(ctx, fmt.Sprintf("ğŸš« [JSONè§£æ] [%s] JSONä¸­æœªæ‰¾åˆ°token usageä¿¡æ¯", connID))
		
		// Fallback: No token information found, mark request as completed with default model
		if a.usageTracker != nil && connID != "" && lifecycleManager != nil {
			emptyTokens := &tracking.TokenUsage{
				InputTokens: 0, OutputTokens: 0, 
				CacheCreationTokens: 0, CacheReadTokens: 0,
			}
			duration := lifecycleManager.GetDuration()
			a.usageTracker.RecordRequestComplete(connID, "non_token_response", emptyTokens, duration)
			slog.InfoContext(ctx, fmt.Sprintf("âœ… [æ— Tokenå®Œæˆ] è¿æ¥: %s å·²æ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€ï¼Œæ¨¡å‹: non_token_response, å¤„ç†æ—¶é—´: %v", 
				connID, duration))
		}
	}
}

// AnalyzeResponseForTokensUnified ç®€åŒ–ç‰ˆæœ¬çš„Tokenåˆ†æï¼ˆç”¨äºç»Ÿä¸€æ¥å£ï¼‰
func (a *TokenAnalyzer) AnalyzeResponseForTokensUnified(responseBytes []byte, connID, endpointName string, lifecycleManager RequestLifecycleManager) {
	if len(responseBytes) == 0 {
		return
	}
	
	responseStr := string(responseBytes)
	
	// ä½¿ç”¨ç°æœ‰çš„Tokenåˆ†ææ–¹æ³•ï¼ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„Requestå¯¹è±¡ï¼‰
	req := &http.Request{} // åˆ›å»ºä¸€ä¸ªç©ºçš„requestå¯¹è±¡
	req = req.WithContext(context.WithValue(context.Background(), "conn_id", connID))
	
	// è°ƒç”¨ç°æœ‰çš„åˆ†ææ–¹æ³•ï¼Œä¼ å…¥lifecycleManagerä»¥è·å–å‡†ç¡®çš„duration
	a.AnalyzeResponseForTokensWithLifecycle(req.Context(), responseStr, endpointName, req, lifecycleManager)
}