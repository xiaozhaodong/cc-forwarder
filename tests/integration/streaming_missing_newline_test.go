package integration

import (
	"context"
	"io"
	"net/http"
	"net/http/httptest"
	"testing"
	"time"

	"cc-forwarder/internal/middleware"
	"cc-forwarder/internal/proxy"
	"cc-forwarder/internal/tracking"
)

// MissingNewlineReader æ¨¡æ‹Ÿåœ¨ message_delta åç›´æ¥ EOFï¼Œä¸å‘é€ç»ˆæ­¢ç©ºè¡Œçš„åœºæ™¯
type MissingNewlineReader struct {
	data     []byte
	position int
}

func (r *MissingNewlineReader) Read(p []byte) (n int, err error) {
	if r.position >= len(r.data) {
		return 0, io.EOF
	}

	n = copy(p, r.data[r.position:])
	r.position += n

	if r.position >= len(r.data) {
		return n, io.EOF
	}

	return n, nil
}

func (r *MissingNewlineReader) Close() error {
	return nil
}

// TestStreamingMissingNewlineFlush æµ‹è¯•ç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œæ—¶çš„ flush æœºåˆ¶
func TestStreamingMissingNewlineFlush(t *testing.T) {
	t.Log("ğŸ§ª æµ‹è¯•å¼€å§‹ï¼šmessage_delta åç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œçš„ flush ä¿®å¤")

	// è®¾ç½®æµ‹è¯•ç¯å¢ƒ
	trackerConfig := &tracking.Config{
		Enabled:       true,
		DatabasePath:  ":memory:",
		BufferSize:    50,
		BatchSize:     5,
		FlushInterval: 50 * time.Millisecond,
		MaxRetry:      2,
		DefaultPricing: tracking.ModelPricing{
			Input:  2.0,
			Output: 10.0,
		},
	}

	tracker, err := tracking.NewUsageTracker(trackerConfig)
	if err != nil {
		t.Fatalf("åˆ›å»º UsageTracker å¤±è´¥: %v", err)
	}
	defer tracker.Close()

	monitoringMiddleware := middleware.NewMonitoringMiddleware(nil)

	// SSE æ•°æ®ï¼šåŒ…å«å®Œæ•´çš„ usage ä¿¡æ¯ï¼Œä½†åœ¨ message_delta åç›´æ¥æ–­æµï¼Œæ²¡æœ‰ç»ˆæ­¢ç©ºè¡Œ
	sseData := `event: message_start
data: {"type":"message_start","message":{"id":"msg_test123","type":"message","role":"assistant","model":"claude-3-5-sonnet-20241022","content":[],"usage":{"input_tokens":100,"output_tokens":0,"cache_creation_input_tokens":0,"cache_read_input_tokens":0}}}

event: message_delta
data: {"type":"message_delta","delta":{"type":"text","text":"Hello"},"usage":{"input_tokens":100,"output_tokens":50,"cache_creation_input_tokens":20,"cache_read_input_tokens":10}}`
	// æ³¨æ„ï¼šè¿™é‡Œæ•…æ„ä¸åŠ ç»ˆæ­¢ç©ºè¡Œï¼Œç›´æ¥ç»“æŸ

	reader := &MissingNewlineReader{
		data:     []byte(sseData),
		position: 0,
	}

	resp := &http.Response{
		StatusCode: 200,
		Body:       reader,
		Header:     make(http.Header),
	}

	// åˆ›å»ºç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
	requestID := "req-missing-newline-001"
	lifecycleManager := proxy.NewRequestLifecycleManager(
		tracker,
		monitoringMiddleware,
		requestID,
		nil, // eventBus åœ¨æµ‹è¯•ä¸­ä¸éœ€è¦
	)

	// lifecycleManager.SetEndpoint("test-endpoint", "test-group")
	// lifecycleManager.StartRequest("192.168.1.100", "test-client", "POST", "/v1/messages", true)
	_ = lifecycleManager // å¿½ç•¥æœªä½¿ç”¨è­¦å‘Š

	// åˆ›å»ºæµå¤„ç†å™¨
	recorder := httptest.NewRecorder()
	flusher := &mockFlusher{}

	tokenParser := proxy.NewTokenParser()
	streamProcessor := proxy.NewStreamProcessor(
		tokenParser,
		tracker,
		recorder,
		flusher,
		requestID,
		"test-endpoint",
	)

	t.Log("ğŸ”„ å¼€å§‹æµå¼å¤„ç†ï¼Œæ¨¡æ‹Ÿç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œçš„åœºæ™¯...")

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	finalTokenUsage, modelName, err := streamProcessor.ProcessStreamWithRetry(ctx, resp)

	// éªŒè¯1ï¼šåº”è¯¥æ­£å¸¸å®Œæˆï¼ˆEOF ä½œä¸ºæµç»“æŸæ ‡å¿—ï¼‰
	if err != nil {
		t.Logf("â„¹ï¸ æ”¶åˆ°é”™è¯¯ï¼ˆå¯èƒ½æ˜¯é¢„æœŸçš„ EOFï¼‰: %v", err)
	}

	// éªŒè¯2ï¼šå…³é”®éªŒè¯ - Token ä¿¡æ¯å¿…é¡»è¢«æ­£ç¡®æ•è·
	if finalTokenUsage == nil {
		t.Error("âŒ FAIL: ç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œå¯¼è‡´ Token ä¿¡æ¯ä¸¢å¤± - flush æœºåˆ¶æœªç”Ÿæ•ˆï¼")
		t.Log("ğŸ’¡ è¿™è¡¨æ˜ flushPendingEvent æœªè¢«æ­£ç¡®è°ƒç”¨æˆ–æœªæ­£å¸¸å·¥ä½œ")
	} else {
		t.Log("âœ… PASS: Token ä¿¡æ¯è¢«æ­£ç¡®ä¿ç•™ï¼ˆflush æœºåˆ¶ç”Ÿæ•ˆï¼‰")
		t.Logf("   è¾“å…¥ Token: %d (æœŸæœ›: 100)", finalTokenUsage.InputTokens)
		t.Logf("   è¾“å‡º Token: %d (æœŸæœ›: 50)", finalTokenUsage.OutputTokens)
		t.Logf("   ç¼“å­˜åˆ›å»º: %d (æœŸæœ›: 20)", finalTokenUsage.CacheCreationTokens)
		t.Logf("   ç¼“å­˜è¯»å–: %d (æœŸæœ›: 10)", finalTokenUsage.CacheReadTokens)

		// éªŒè¯æ•°å€¼ç²¾ç¡®æ€§
		if finalTokenUsage.InputTokens != 100 {
			t.Errorf("âŒ è¾“å…¥ Token ä¸åŒ¹é…: æœŸæœ› 100, å®é™… %d", finalTokenUsage.InputTokens)
		}
		if finalTokenUsage.OutputTokens != 50 {
			t.Errorf("âŒ è¾“å‡º Token ä¸åŒ¹é…: æœŸæœ› 50, å®é™… %d", finalTokenUsage.OutputTokens)
		}
		if finalTokenUsage.CacheCreationTokens != 20 {
			t.Errorf("âŒ ç¼“å­˜åˆ›å»º Token ä¸åŒ¹é…: æœŸæœ› 20, å®é™… %d", finalTokenUsage.CacheCreationTokens)
		}
		if finalTokenUsage.CacheReadTokens != 10 {
			t.Errorf("âŒ ç¼“å­˜è¯»å– Token ä¸åŒ¹é…: æœŸæœ› 10, å®é™… %d", finalTokenUsage.CacheReadTokens)
		}

		if finalTokenUsage.InputTokens == 100 &&
		   finalTokenUsage.OutputTokens == 50 &&
		   finalTokenUsage.CacheCreationTokens == 20 &&
		   finalTokenUsage.CacheReadTokens == 10 {
			t.Log("ğŸ¯ æ‰€æœ‰ Token æ•°å€¼å®Œå…¨åŒ¹é…ï¼flush ä¿®å¤æ–¹æ¡ˆæˆåŠŸ")
		}
	}

	// éªŒè¯3ï¼šæ¨¡å‹åç§°
	if modelName != "claude-3-5-sonnet-20241022" {
		t.Errorf("âŒ æ¨¡å‹åç§°ä¸åŒ¹é…: æœŸæœ› 'claude-3-5-sonnet-20241022', å®é™… '%s'", modelName)
	} else {
		t.Logf("âœ… æ¨¡å‹åç§°æ­£ç¡®: %s", modelName)
	}

	// éªŒè¯4ï¼šç¡®è®¤ empty_response ä¸ä¼šå‡ºç°
	if finalTokenUsage != nil {
		hasTokens := finalTokenUsage.InputTokens > 0 || finalTokenUsage.OutputTokens > 0
		if hasTokens {
			t.Log("âœ… æœ‰çœŸå® Tokenï¼Œä¸ä¼šè¢«è¯¯åˆ¤ä¸º empty_response")
		}
	}

	t.Log("ğŸ¯ ç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œçš„ flush ä¿®å¤æµ‹è¯•å®Œæˆ")
}

// TestTokenParserFlushMethod ç›´æ¥æµ‹è¯• TokenParser çš„ flushPendingEvent æ–¹æ³•
func TestTokenParserFlushMethod(t *testing.T) {
	t.Log("ğŸ§ª æµ‹è¯•å¼€å§‹ï¼šTokenParser.flushPendingEvent() æ–¹æ³•å•å…ƒæµ‹è¯•")

	tokenParser := proxy.NewTokenParserWithRequestID("req-flush-test")

	// åœºæ™¯1ï¼šè§£æ message_deltaï¼Œä½†ä¸å‘é€ç»ˆæ­¢ç©ºè¡Œ
	t.Log("ğŸ“ åœºæ™¯1ï¼šæ¨¡æ‹Ÿç¼ºå°‘ç»ˆæ­¢ç©ºè¡Œçš„ message_delta äº‹ä»¶")

	// è§£æ event è¡Œ
	result1 := tokenParser.ParseSSELineV2("event: message_delta")
	if result1 != nil {
		t.Error("âŒ event è¡Œä¸åº”è¿”å›ç»“æœ")
	}

	// è§£æ data è¡Œï¼ˆåŒ…å« usageï¼‰
	result2 := tokenParser.ParseSSELineV2(`data: {"type":"message_delta","delta":{"type":"text","text":"Test"},"usage":{"input_tokens":200,"output_tokens":100,"cache_creation_input_tokens":30,"cache_read_input_tokens":15}}`)
	if result2 != nil {
		t.Error("âŒ data è¡Œä¸åº”è¿”å›ç»“æœï¼ˆç­‰å¾…ç©ºè¡Œï¼‰")
	}

	// æ­¤æ—¶åº”è¯¥æ²¡æœ‰ç©ºè¡Œè§¦å‘è§£æï¼ŒeventBuffer ä¸­æœ‰æ•°æ®
	// ç°åœ¨è°ƒç”¨ flushPendingEvent å¼ºåˆ¶è§£æ
	t.Log("ğŸ”„ è°ƒç”¨ flushPendingEvent å¼ºåˆ¶è§£æ...")
	flushResult := tokenParser.FlushPendingEvent()

	if flushResult == nil {
		t.Error("âŒ FAIL: flushPendingEvent è¿”å› nilï¼Œæœªèƒ½è§£æç¼“å­˜çš„äº‹ä»¶")
	} else {
		t.Log("âœ… PASS: flushPendingEvent æˆåŠŸè¿”å›è§£æç»“æœ")

		if flushResult.TokenUsage == nil {
			t.Error("âŒ Token ä½¿ç”¨ä¿¡æ¯ä¸º nil")
		} else {
			t.Logf("   è¾“å…¥ Token: %d (æœŸæœ›: 200)", flushResult.TokenUsage.InputTokens)
			t.Logf("   è¾“å‡º Token: %d (æœŸæœ›: 100)", flushResult.TokenUsage.OutputTokens)
			t.Logf("   ç¼“å­˜åˆ›å»º: %d (æœŸæœ›: 30)", flushResult.TokenUsage.CacheCreationTokens)
			t.Logf("   ç¼“å­˜è¯»å–: %d (æœŸæœ›: 15)", flushResult.TokenUsage.CacheReadTokens)

			if flushResult.TokenUsage.InputTokens != 200 ||
				flushResult.TokenUsage.OutputTokens != 100 ||
				flushResult.TokenUsage.CacheCreationTokens != 30 ||
				flushResult.TokenUsage.CacheReadTokens != 15 {
				t.Error("âŒ Token æ•°å€¼ä¸åŒ¹é…")
			} else {
				t.Log("ğŸ¯ æ‰€æœ‰ Token æ•°å€¼å®Œå…¨æ­£ç¡®ï¼")
			}
		}
	}

	// åœºæ™¯2ï¼šæµ‹è¯•æ²¡æœ‰å¾…å¤„ç†äº‹ä»¶æ—¶çš„è¡Œä¸º
	t.Log("ğŸ“ åœºæ™¯2ï¼šæ²¡æœ‰å¾…å¤„ç†äº‹ä»¶æ—¶è°ƒç”¨ flush")
	tokenParser.Reset()
	emptyFlushResult := tokenParser.FlushPendingEvent()
	if emptyFlushResult != nil {
		t.Error("âŒ æ²¡æœ‰å¾…å¤„ç†äº‹ä»¶æ—¶åº”è¿”å› nil")
	} else {
		t.Log("âœ… æ­£ç¡®è¿”å› nil")
	}

	t.Log("ğŸ¯ TokenParser.flushPendingEvent() å•å…ƒæµ‹è¯•å®Œæˆ")
}